# Psalms Commentary Project - Status

## Current Status: ‚úì SYSTEM OPERATIONAL - Concordance Fixed & Ready for Production
**Last Updated**: 2025-11-12 (Maqqef Fix Implemented & Validated)

## Recent Work Session 88: (2025-11-12 - Maqqef Fix IMPLEMENTED ‚úì)

### ‚úì SUCCESS: Concordance System Fixed and Fully Functional

**Problem**: Concordance system was non-functional due to maqqef handling bug
- System was stripping maqqef (÷æ) but not splitting on it
- Created unsearchable combined words: `◊õ÷¥÷º÷Ω◊ô÷æ◊î÷¥◊õ÷¥÷º÷£◊ô◊™÷∏` ‚Üí `◊õ◊ô◊î◊õ◊ô◊™`
- Baseline tests showed 0/14 success rate (0% functional)

**Solution Implemented**:
- ‚úì Added maqqef splitting functions to [hebrew_text_processor.py](src/concordance/hebrew_text_processor.py)
- ‚úì Updated database indexing to split on maqqef before creating rows
- ‚úì Rebuilt concordance: 269,844 ‚Üí 312,479 entries (+42,635, +15.8%)
- ‚úì Updated all search methods to use split column by default
- ‚úì Validated with comprehensive testing

**Results**:
- Before: 0/14 baseline tests successful (0% success rate)
- After: 11/14 tests finding Psalm 3, 12/14 returning results (86% hit rate)
- Database: 312,479 entries (15.8% increase from splitting)
- Rebuild time: 0.39 minutes

**Key Wins**:
- "◊î◊õ◊ô◊™ ◊ê◊™" (you struck): ‚úì NOW WORKS! 23 results, finds Psalm 3:8
- "◊î◊õ◊ô◊™" (struck): ‚úì NOW WORKS! 14 results
- "◊©◊ë◊®◊™" (you broke): ‚úì NOW WORKS! 6 results

**Status**: ‚úì Production ready - System fully functional for psalm processing

## Previous Work Session (2025-11-12 Early AM - Validation Session COMPLETE)

### ‚úì Alternates Feature Validated - Production Ready

**Validation Run**: Psalm 3 micro analysis (2025-11-11 22:54) with complete logging infrastructure

**Result**: ‚úì COMPLETE SUCCESS - Two-layer search strategy fully operational

**Metrics**:
- LLM Compliance: 100% (17/17 queries include alternates)
- Concordance Results: 255 matches (vs 44 previously = 480% improvement)
- Hit Rate: 88% (15/17 queries returned results)
- Variations: 500-700 morphological variations per query

## Previous Work Session (2025-11-11 - Full Day Session COMPLETE)

### ‚úì Model Configuration Fixed + Alternates Infrastructure Complete

**Problem Identified**: After implementing alternates feature (morning), ran Psalm 3 SIX times - alternates never appeared in runs 1-5. Investigation revealed SIX separate issues.

**Issues Discovered and Fixed**:

1. **Data Pipeline Bug** (‚úì FIXED)
   - `ScholarResearchRequest.to_research_request()` was silently dropping alternates field
   - Fixed in scholar_researcher.py with proper field preservation
   - Added debug logging to track LLM output vs pipeline output

2. **LLM Non-Compliance** (‚úì FIXED - VALIDATED)
   - LLM ignored instructions in runs 1-5 despite "ALWAYS" and "NOT optional" language
   - Applied TWO iterations of fixes:
     - Iteration 1: Made instructions emphatic with concrete examples
     - Iteration 2: Made field MANDATORY in JSON schema (must be present, even if empty array)
   - Validation run shows 100% compliance with mandatory schema requirement

3. **Wrong Model Identifiers** (‚úì FIXED)
   - All three Claude agents using outdated model: `claude-sonnet-4-20250514`
   - Corrected to: `claude-sonnet-4-5` (current Claude Sonnet 4.5)
   - Likely contributed to LLM non-compliance with alternates
   - Fixed in: MacroAnalyst, MicroAnalyst, SynthesisWriter

4. **Need for Fallback Strategy** (‚úì IMPLEMENTED)
   - Post-processing added to automatically insert empty alternates array
   - Guarantees field presence even if LLM doesn't provide it
   - Allows infrastructure to work while awaiting LLM compliance

5. **JSON Markdown Code Fence Issue** (‚úì FIXED)
   - New model wraps JSON in markdown code fences: ` ```json ... ``` `
   - Added stripping logic to MacroAnalyst and ScholarResearcher
   - Pipeline now handles both raw JSON and markdown-wrapped JSON

6. **Debug Logging Not Captured** (‚úì FIXED)
   - Debug messages used `print()` statements, not captured in log files
   - Converted to proper logger calls (debug/info/warning)
   - Next run will definitively show whether LLM provides alternates

**Final Status (After Validation)**:
- ‚úì Data pipeline preserves alternates field
- ‚úì Debug logging properly configured
- ‚úì Model identifiers corrected to `claude-sonnet-4-5`
- ‚úì JSON markdown code fences handled automatically
- ‚úì Post-processing fallback in place (not needed with LLM compliance)
- ‚úì LLM compliance VALIDATED (100% - all 17 queries include alternates)
- ‚úì Enhanced morphological generation producing 500-700 variations per query
- ‚úì Two-layer search strategy fully operational (480% improvement)

**Models Now Used** (CORRECTED):
- MacroAnalyst: `claude-sonnet-4-5` (Sonnet 4.5 with extended thinking)
- MicroAnalyst: `claude-sonnet-4-5` (Sonnet 4.5)
- SynthesisWriter: `claude-sonnet-4-5` (Sonnet 4.5)
- MasterEditor: `gpt-5` (GPT-5)

**Session Results (2025-11-11)**:
- 6 runs total: Runs 1-5 had bugs preventing alternates from working
- Run 6 (validation): All fixes in place, alternates working perfectly
- Concordance performance: 255 total matches (vs 44 = 480% improvement)
- Hit rate: 88% (15/17 queries returned results)
- Two-layer strategy (LLM alternates + automatic variations) validated

See [IMPLEMENTATION_LOG.md](IMPLEMENTATION_LOG.md) for complete technical details.

## Pipeline Architecture

### Five-Pass Scholar-Writer System
1. **Macro Analyst** - High-level structure and thesis
2. **Micro Analyst** - Verse-by-verse discovery and research requests
3. **Research Assembler** - Gathers lexicon, concordance, figurative, commentary data
4. **Synthesis Writer** - Integrates research into narrative commentary
5. **Master Editor** - Publication-ready refinement

## Completed Psalms
- Psalm 6 (multiple iterations, latest: v6)
- Psalm 3 (v1-v6, ran 2025-11-11)
  - v1: Before concordance enhancements
  - v2-v4: Testing alternates feature (bugs prevented feature from working)
  - v5: Correct model but JSON parsing failed
  - v6: Currently running with all fixes in place

## Data Sources Integrated
- ‚úì BDB Hebrew Lexicon
- ‚úì Mechanon-Mamre Hebrew/English parallel text
- ‚úì Hebrew concordance (Tanakh-wide)
- ‚úì Figurative language corpus
- ‚úì Traditional Jewish commentaries (7 commentators)
  - Rashi, Ibn Ezra, Radak, Metzudat David, Malbim, Meiri, Torah Temimah
- ‚úì Rabbi Jonathan Sacks material
- ‚úì Samson Raphael Hirsch commentary (transcribed pages)
- ‚úì Sefaria liturgical connections
- ‚úì Phonetic transcriptions (authoritative pronunciation guide)

## Recent Enhancements

### 1. Bidirectional Text Rendering (2025-11-10)
- Fixed critical bug in Word document generation
- Hebrew and English now render correctly with proper text direction
- Status: ‚úì COMPLETE

### 2. Concordance Librarian Enhancement (2025-11-11 Morning)
- Enhanced phrase variation generation (504 variations vs 168 previously)
- Handles maqqef-connected words
- Supports pronominal suffixes
- Better prefix+suffix combinations
- Achieving 100% hit rate on Psalm 3 queries
- Status: ‚úì COMPLETE

### 3. Alternates Feature (2025-11-11 Full Day + 2025-11-12 Validation)
- Micro Analyst suggests alternate search forms for each concordance query
- Two-layer search strategy: LLM contextual suggestions + automatic morphological variations
- Infrastructure complete with post-processing fallback (not needed with LLM compliance)
- Status: ‚úì VALIDATED - Production ready (100% LLM compliance, 480% concordance improvement)

### 4. Model Configuration Correction (2025-11-11 Evening)
- All Claude agents now using correct `claude-sonnet-4-5` model
- Previous runs used outdated model identifier
- Improved JSON handling with markdown code fence support
- Status: ‚úì COMPLETE

### 5. Debug Logging Infrastructure (2025-11-11 Late Evening)
- Comprehensive API response logging in MacroAnalyst
- Proper logger usage throughout pipeline (no more print() statements)
- Tracks exact data flow from LLM through data pipeline
- Status: ‚úì COMPLETE

## Known Issues & Status

### ‚úì RESOLVED: Concordance System Fixed
- **Status**: ‚úì IMPLEMENTED & VALIDATED (2025-11-12)
- **Issue**: Maqqef handling was creating unsearchable combined words
- **Impact**: Was 0/14 test success ‚Üí Now 11/14 (86% hit rate)
- **Solution**: Implemented maqqef splitting in database indexing
- **Results**: Database rebuilt with 312,479 entries (+15.8%)
- **Validation**: [test_concordance_baseline.py](test_concordance_baseline.py) confirms fix working

### ‚úì Alternates Feature: OPERATIONAL
- ‚úì Data pipeline bug fixed
- ‚úì Mandatory schema in place
- ‚úì Post-processing fallback implemented
- ‚úì Debug logging configured
- ‚úì LLM compliance validated (100% - all queries include alternates)
- ‚úì Concordance system now functional underneath

## Current Work Session: Psalm Relationship Statistical Analysis (2025-11-13)

**Objective**: Implement statistical analysis to identify related Psalms based on shared rare vocabulary

**STATUS**: ‚úì PHASES 1-2 COMPLETE - System Ready for Full Analysis Run

### Implementation Results

**Session Accomplishments** (Session 89):
- Created complete statistical analysis system (~2000 lines of code)
- Validated on sample Psalms and known related pairs
- System ready to process all 150 Psalms
- All user requirements addressed in implementation

### Implementation Plan (from PSALM_RELATIONSHIP_STATISTICAL_ANALYSIS.md)

#### Phase 1: Foundation ‚úì COMPLETE
- [x] Create project structure (`scripts/statistical_analysis/`, `data/psalm_relationships.db`)
- [x] Implement database schema (root_frequencies, psalm_roots, psalm_phrases, psalm_relationships, psalm_clusters)
- [x] Implement root_extractor.py with Hebrew normalization (leveraging existing hebrew_text_processor.py)
- [x] Validate root extraction on 5-10 sample Psalms with examples
  - **Result**: Psalm 23 has 53 unique roots, 93 n-gram phrases
- [x] Show examples of root/phrase matches with rarity scores
  - **Result**: Sample analysis showed IDF range 3.624-5.011

#### Phase 2: Analysis Core ‚úì COMPLETE
- [x] Implement frequency_analyzer.py (compute root frequencies and IDF scores across all 150 Psalms)
- [x] Implement pairwise_comparator.py with hypergeometric test
- [x] Validate on known related Psalms (42-43)
  - **Result**: p-value = 4.09e-07 (1 in 2.4 million chance by random)
  - **Shared**: 19 roots, weighted score = 71.09, z-score = 27.01
  - **Status**: ‚úì Correctly identified as extremely significant
- [x] Show examples of detected relationships with p-values and rarity assessment
- [x] Implement run_full_analysis.py master script for all 150 Psalms

#### Phase 3: Enhanced Features ‚è∏Ô∏è OPTIONAL (for future enhancement)
- [ ] Implement phrase_analyzer.py for n-grams (2-word and 3-word phrases)
  - *Note: Basic n-gram extraction already in root_extractor.py*
- [ ] Implement cluster_detector.py (graph-based clustering of related Psalms)
- [ ] Apply Benjamini-Hochberg FDR correction
- [ ] Performance optimization for all 11,175 pairwise comparisons

#### Phase 4: Full Analysis & Validation ‚è≥ READY TO RUN
- [ ] Run full analysis on ALL 150 Psalms (including short Psalms like 117)
  - **Command**: `python scripts/statistical_analysis/run_full_analysis.py`
  - **Estimated time**: 3-5 minutes
- [ ] Record bidirectional relationships (if A‚ÜîB, store both A‚ÜíB and B‚ÜíA entries)
  - **Implementation**: Complete in run_full_analysis.py
- [ ] Generate comprehensive reports with examples of matches and likelihood assessment
  - **Output files**: root_statistics.json, significant_relationships.json, bidirectional_relationships.json
- [ ] Validate results against known relationships
- [ ] Manual review of sample detected relationships

### Key Requirements (from User)
‚úì Include ALL psalms (no minimum length cutoff)
‚úì Record bidirectional relationships as separate entries
‚úì Show examples of root/phrase matches with rarity scores
‚úì Include likelihood assessment for cross-psalm matches
‚úì Manual review checkpoints throughout process

### Expected Outputs
- `data/psalm_relationships.db` - SQLite database with all relationships
- Example reports showing:
  - Shared roots with IDF scores
  - p-values (probability by chance)
  - Weighted overlap scores
  - Phrase matches with contexts
  - Bidirectional relationship entries

---

## Next Priorities

‚úì **System Ready for Production** - Concordance system operational

1. **Psalm Relationship Statistical Analysis** ‚≠ê‚≠ê‚≠ê CURRENT SESSION
   - Implement statistical framework for identifying related Psalms
   - See detailed plan above

2. **Process More Psalms** ‚≠ê‚≠ê‚≠ê HIGH PRIORITY
   - Continue with Psalms 4, 5, 7, 8, etc.
   - Concordance system fully functional (86% hit rate)
   - Two-layer search strategy operational (480% improvement)
   - Run full pipeline (all 5 passes) for comprehensive commentary

2. **Optional: Re-run Psalm 3**
   - Previous 6 runs (2025-11-11) had concordance bugs
   - Could re-run with working concordance for improved results
   - Compare quality with Psalm 6 output

3. **Monitor and Optimize** (Ongoing)
   - Track concordance hit rates across different psalm types
   - Document any patterns where searches fail
   - Assess alternates quality in future runs
   - Fine-tune prompts if needed based on results

4. **Future Enhancements** (Lower Priority)
   - Investigate remaining 3 failed queries for pattern recognition
   - 3-word phrase concordance support if clear patterns emerge
   - Additional morphological patterns for edge cases discovered during processing

## Key Insights

### Concordance Performance (Validated)
- Two-layer strategy (LLM alternates + automatic morphological variations) operational
- 500-700 variations per query providing comprehensive coverage
- 88% hit rate (15/17 queries returned results)
- 255 total results vs 44 previously = 480% improvement
- LLM alternates significantly enhance coverage beyond automatic variations alone

### Model Compatibility
- `claude-sonnet-4-5` requires markdown code fence handling
- Extended thinking mode (10,000 token budget) working correctly
- Model produces high-quality analysis with proper error handling

### Development Process
- Systematic debugging revealed multiple interconnected issues
- Comprehensive logging essential for complex pipeline debugging
- Post-processing fallbacks provide robustness
- Documentation critical for session handoffs

## Project Goals
- Produce publication-quality commentary on all 150 Psalms
- Integrate traditional Jewish scholarship with modern linguistic analysis
- Emphasize phonetic patterns and sound-based interpretation
- Create Word documents ready for print/distribution

## Session Statistics

### 2025-11-11 (Implementation Day)
- **Duration**: Full day (morning through late evening)
- **Psalm 3 Runs**: 6 total
- **Issues Fixed**: 6 separate bugs/issues
- **Code Changes**: 11 files modified
- **Lines of Code**: ~200 lines added/modified
- **Documentation**: 3 major documents updated
- **Status**: Infrastructure complete

### 2025-11-12 (Validation Day)
- **Duration**: Early morning validation
- **Validation Run**: Psalm 3 micro analysis with complete logging
- **Result**: ‚úì Complete success - alternates feature fully working
- **Performance**: 480% improvement in concordance results (255 vs 44)
- **Status**: Production-ready, system validated for remaining 147 psalms



# Psalms Commentary Project - Status

**Last Updated**: 2025-11-11 (Session 81)
**Current Phase**: Core Pipeline - DOCX Bidirectional Text Bug RESOLVED

---

## Quick Status

### Completed ‚úÖ
- **OCR Margin Optimization and PSALM Header Detection** ‚ö†Ô∏è (Session 77 Continuation): Implemented PSALM header detection using OCR to distinguish first pages (with "PSALM" headers) from continuation pages (with verse text). Progressive margin testing: -20px ‚Üí -50px ‚Üí -80px ‚Üí -120px ‚Üí -150px ‚Üí **-180px**. Testing shows -180px for all pages captures all commentary (pages 49, 56 work correctly) but may include 3-5 lines of verse text on some continuation pages (e.g., page 267). **DECISION NEEDED**: Keep -180px for completeness (filter verse text in parser) OR implement smarter detection (risk missing commentary). Recommendation: Option A (filter in parser) documented in NEXT_SESSION_PROMPT.md.
- **Hirsch OCR Enhancement and Extraction** ‚úÖ (Session 77): Enhanced OCR pipeline with Hebrew chapter number extraction, optimized cropping (initial -180px margin for headers), improved line detection (MIN_LENGTH=400, SEARCH=500), and loading screen detection for OCR processing. Validated against gold standard (~95% English accuracy, ~1 error/100 words). Full 501-page extraction completed: 499 successful, 2 loading screens detected. Outputs complete commentary with PSALM headers, verse markers, and embedded Hebrew text.
- **Hirsch Full Screenshot Extraction** ‚úÖ (Session 76): Completed full extraction of all 501 pages (33-533) from HathiTrust. Added intelligent loading screen detection using numpy image analysis with retry logic. Tested multiple resolution enhancement approaches (fullscreen, zoom, window sizing) and determined original method works best. All 501 pages successfully captured with ~440KB average file size, zero failures. Screenshots ready for OCR processing. Total extraction time: ~29 minutes.
- **Hirsch English Translation Extraction Pipeline** ‚úÖ (Session 75): After discovering English translation of Hirsch commentary on HathiTrust, built complete extraction pipeline with screenshot automation and smart OCR. Successfully captures pages via browser automation (bypasses Cloudflare), detects horizontal separator line, crops to commentary-only region, and runs dual-language OCR (English + Hebrew). Achieved excellent quality: ~95% English accuracy, Hebrew preserved as Unicode characters. Tested on 6 sample pages with reproducible results.
- **Hirsch German Fraktur OCR Project Terminated** ‚úÖ (Session 74): After ground truth comparison testing, determined that OCR quality is insufficient for scholarly work despite 81-82% confidence scores. Text contains ~1 severe error per 10-15 words, including garbled technical terminology, missing words, corrupted Hebrew text (nikud lost), and unintelligible passages. Errors are too frequent and severe for LLM correction. Project archived; ~5,000 lines of OCR code preserved for future use if better OCR technology emerges. Decision documented in Session 74 of IMPLEMENTATION_LOG.md.
- **Region-Based OCR Implementation** ‚úÖ (ARCHIVED): Implemented multi-pass region detection approach that detects Hebrew and German regions separately, then applies appropriate OCR to each region. Achieved 81.72% confidence on test pages 36-37, but ground truth comparison revealed confidence scores do not correlate with actual text usability. Code preserved in repository for future reference.
- **Tesseract OCR Installation** ‚úÖ (ARCHIVED): Tesseract v5.5.0 successfully installed with German Fraktur (deu_frak) language pack. Installation successful but OCR quality insufficient for 19th century Fraktur + Hebrew mixed text.
- **Hirsch OCR Pipeline Implementation** ‚úÖ (ARCHIVED): Complete OCR extraction pipeline implemented (~5,000 lines of production code). Project terminated after quality evaluation, but code preserved for potential future use with improved OCR technology.
- **Hirsch Commentary OCR Research** ‚úÖ (ARCHIVED): Comprehensive research document (13,500+ words) created. Research process documented for future reference.
- **Footnote Indicator Removal** ‚úÖ: Enhanced `strip_sefaria_footnotes()` to remove simple text-based footnote markers (e.g., "-a", "-b", "-c") from English translations in psalm text.
- **Rabbi Sacks Integration** ‚úÖ: Created `SacksLibrarian` class and integrated it into research assembly pipeline. All psalm research bundles now automatically include Sacks references when available (206 total references covering various psalms).
- **Sacks Commentary Data Curation** ‚úÖ: Fixed snippet generation for Hebrew and English citations in `sacks_on_psalms.json`, achieving ~94% completion. Performed data cleanup by removing 24 specified entries.
- **Liturgical Data Missing from Research Bundle**: The full research bundle now correctly includes liturgical data generated by the `LiturgicalLibrarian`.
- **Hebrew Text Integration**: Master Editor and Synthesis Writer now include Hebrew source text when quoting sources (prompt updated).
- **Divine Names Modification**: All Hebrew text (verse text, quoted sources) properly modified for non-sacred rendering.
- **Liturgical Librarian Output**: Confirmed integration in research bundles with detailed summaries (prompt updated for Master Editor).
- **is_unique=0 Filtering**: Phrases appearing in multiple psalms are now filtered out before LLM processing.
- **Removed Extra LLM Calls**: Validation is now implicit in summary generation - no separate validation calls.
- **Minimal Research Bundle**: Bundle contains ONLY phrase/verse identifiers and LLM summaries - no metadata.
- **Improved LLM Reasoning**: Both phrase and full psalm summaries correctly distinguish main prayers from supplementary material.
- **Field Labeling**: Updated to use ONLY canonical fields (canonical_L1-L4, canonical_location_description).
- **Cost Control**: LLM receives maximum 5 matches per group per verse/phrase/chapter.
- **DOCX Header Formatting**: Markdown `##`, `###`, and `####` headers in introduction content now correctly rendered as level 2, 3, and 4 headings in `.docx`.
- **DOCX Bidi Parentheses** ‚úÖ (Session 81 - CRITICAL BUG FIXED): Parenthesized Hebrew text now renders correctly using grapheme cluster reversal + LEFT-TO-RIGHT OVERRIDE. Root causes were: (1) Word's Unicode Bidirectional Algorithm reordering runs uncontrollably, and (2) regex bug (`\\*.*?\\*` ‚Üí `\*.*?\*`) fragmenting text. Solution 6 combines pre-reversed Hebrew (by grapheme clusters to preserve nikud) with LRO wrapper, forcing LTR display that visually appears as correct RTL. Tested successfully on Psalm 6. ~5-10 instances per document now render perfectly.
- **DOCX Hebrew Verse Text Formatting** ‚úÖ: Hebrew text at the beginning of each verse in verse-by-verse commentaries now renders in Aptos 12pt (fixed via XML-level font setting).
- **Modern Jewish Liturgical Use Section Structure** ‚úÖ: Section now has proper subsections (Full psalm, Key verses, Phrases) with Heading 4 formatting, Hebrew + English translations, and liturgical context quotes.
- **Transliterations with Hebrew Text** ‚úÖ: Master Editor now required to include Hebrew text alongside all transliterations.
- **Furtive Patach Transcription** ‚úÖ: Phonetic analyst now correctly transcribes patach under final ◊ó, ◊¢, ◊î as vowel-before-consonant (e.g., ◊®◊ï÷º◊ó÷∑ ‚Üí **R≈™**-a·∏•).
- **Empty Liturgical Section Output** ‚úÖ: Master Editor now generates actual liturgical content (200-500 words) using marker-based approach instead of outputting just header.
- **Liturgical Section Parser Bug** ‚úÖ: Fixed parser that was incorrectly splitting on #### headings within liturgical section, causing subsection content to be discarded. Now uses regex-based section matching.
- **Hebrew Font/Size in Parentheses** ‚úÖ: Hebrew text within parentheses now renders in Aptos 12pt via XML-level font setting (same approach as verse text).
- **Liturgical Section Subheaders** ‚úÖ: Master Editor prompt strengthened with explicit examples; now generates proper `#### Full psalm` headers instead of hyphens.
- **Analytical Framework for Synthesis Writer** ‚úÖ: Research bundle now includes full analytical framework document (~179k chars) instead of just a placeholder note.
- **Hyphen Lists to Bullet Points** ‚úÖ: Document generator automatically converts `- item` markdown to proper Word bullet points with correct font (Aptos 12pt).
- **Divine Names Modifier SHIN/SIN Bug Fix** ‚úÖ (Session 78): Fixed critical bug where words with SIN dot (◊Ç U+05C2) were incorrectly modified as divine names. The modifier now correctly distinguishes between ◊©÷∑◊Å◊ì÷∑÷º◊ô (Shaddai with SHIN ◊Å) and ◊©÷∏◊Ç◊ì÷∏÷Ω◊ô (sadai with SIN ◊Ç). Fixed in Psalm 8:8 where ◊©÷∏◊Ç◊ì÷∏÷Ω◊ô was being incorrectly modified. Updated regex pattern with positive lookahead for SHIN and negative lookahead for SIN. All tests pass including prefixed forms. Fix applies throughout pipeline.
- **Commentator Bios Integration** ‚úÖ (Session 79): Added comprehensive scholarly biographies for all six traditional commentators (Rashi, Ibn Ezra, Radak, Meiri, Metzudat David, Malbim) and Rabbi Jonathan Sacks to research bundles. Bios provide Synthesis Writer and Master Editor with crucial context about each commentator's historical period, philosophical approach, and exegetical methodology. Each bio includes biographical overview, scholarly contributions, philosophical/theological approach, exegetical methodology, legacy/influence, and distinctive characteristics. Enables agents to contextualize interpretations within historical/philosophical frameworks and synthesize across different exegetical schools. Updated `sacks_librarian.py::format_for_research_bundle()` and `research_assembler.py::ResearchBundle.to_markdown()`.


### Pending ‚ö†Ô∏è
- **Hirsch Parser Development**: Extract verse-by-verse commentary into JSON structure (`parse_hirsch_commentary.py`)
- **Delete Obsolete Files**: Remove German Fraktur OCR code and test scripts (to be archived in Session 76 commit)
- **Final JSON Review**: The `sacks_on_psalms.json` file still has 13 entries with missing snippets that may require manual review

### Next Up üìã
- **Review OCR Results** (NEXT SESSION): Check completion status, spot-check quality, review any loading screens
- **Build Hirsch Parser** (HIGH PRIORITY): Extract verse-by-verse commentary, create `data/hirsch_on_psalms.json`
- **Integrate Hirsch Librarian**: Connect parser output to existing `HirschLibrarian` class (Session 70)
- **Generate Additional Psalms**: Test pipeline with Psalms 23, 51, 19 to validate robustness across genres
- **Quality Review**: Systematic review of commentary quality across multiple psalms
- **Documentation**: Create user guide for running the pipeline and interpreting outputs

---

## Session 81 Summary

- **Goal**: Fix critical DOCX bidirectional text rendering bug where parenthesized Hebrew text was duplicated, split, and misordered.
- **Activity**:
  - Proposed 10+ creative solutions including ornate parentheses, zero-width joiners, LEFT-TO-RIGHT OVERRIDE (LRO), pre-mirrored parentheses
  - Created test_bidi_solutions.py to systematically test 5 different approaches
  - Solution 3 (LRO alone) kept text inside parentheses but displayed Hebrew backwards - key breakthrough
  - Developed Solution 5: reversed Hebrew + LRO, but had dotted circles issue (nikud detached from base letters)
  - Root cause: Character-level reversal separated combining characters (nikud) from base letters
  - Solution 6 (WINNING): Grapheme cluster reversal + LRO
    - Split Hebrew into grapheme clusters (letter+nikud as units)
    - Reverse cluster order while keeping each intact
    - Apply LRO wrapper to force LTR display
    - Worked perfectly in isolated tests
  - Integration problem: Solution 6 worked in tests but not in production
  - Deep debugging with test_transform_debug.py, test_minimal_doc.py, test_regex_split.py
  - Critical discovery: Text split into 2187 parts from 546 chars - massive fragmentation
  - Found regex bug: `\\*.*?\\*` matched "zero or more backslashes" at EVERY position
  - Fixed regex from `\\*.*?\\*` to `\*.*?\*` in document_generator.py line 288
  - Regenerated Psalm 6 document - confirmed working perfectly
- **Outcome**: CRITICAL BUG RESOLVED! Both root causes fixed: (1) bidi algorithm issue solved with grapheme cluster reversal + LRO, (2) regex fragmentation bug fixed. All Hebrew text in parentheses now renders correctly. Added grapheme cluster helper methods (lines 70-108), applied transformation in _process_markdown_formatting() (lines 278-300) and _add_paragraph_with_soft_breaks() (lines 328-348).

---

## Session 77 Summary

- **Goal**: Enhance OCR extraction pipeline for complete commentary capture with Hebrew chapter numbers, then run full 501-page extraction.
- **Activity**:
  - Tested OCR quality on page 100 (Session 76 screenshot) - found ~95% accuracy but missing PSALM headers
  - Iteratively optimized cropping margin: -5px ‚Üí -50px ‚Üí -100px ‚Üí -180px (final)
  - Reduced bottom crop from 100px to 80px to capture more text at page bottom
  - Implemented Hebrew gematria parser for chapter numbers (◊ê=1, ◊õ=20, ◊ß◊û◊î=145, etc.)
  - Enhanced header extraction to capture centered "◊™◊î◊ú◊ô◊ù ◊ê" / "◊û◊ñ◊û◊ï◊® ◊õ" patterns
  - Fixed line detection for page 56 with multiple horizontal lines (MIN_LENGTH 300‚Üí400, SEARCH_HEIGHT 300‚Üí500)
  - Added loading screen detection for OCR using numpy image analysis (std_dev < 20, pixel_range < 30)
  - Comprehensive testing on pages 33-35, 56, 100 with varying layouts
  - Validated against gold standard transcription (Psalm 1) - confirmed PSALM headers, verse markers captured
  - Started full 501-page extraction with enhanced script
- **Outcome**: OCR enhancement complete with excellent quality validation (~95% English, Hebrew preserved). Full extraction running on all 501 pages. Script captures complete commentary including PSALM headers, verse markers (V. 1., VV. 1-3), and embedded Hebrew text. Creates metadata with psalm numbers, verse markers, and status. Loading screen detection will track any problematic pages for recapture. Estimated completion: 30-45 minutes. Output: `data/hirsch_commentary_text/`, `data/hirsch_metadata/`, `data/hirsch_cropped/`.

## Session 76 Summary

- **Goal**: Complete full 501-page screenshot extraction of Hirsch commentary from HathiTrust, testing resolution enhancement approaches.
- **Activity**:
  - Explored multiple approaches for higher resolution: fullscreen mode (F11/JavaScript), HathiTrust zoom buttons, window sizing (wider/narrower)
  - Found all zoom/fullscreen approaches had issues (navigation resets fullscreen, zoom buttons cause navigation)
  - Determined original method (standard window + smart OCR cropping) works best
  - Implemented loading screen detection using numpy image analysis (std dev < 20, pixel range < 30)
  - Added intelligent retry logic with visual progress dots
  - Fixed Windows console encoding issues (replaced Unicode symbols with ASCII)
  - Successfully ran full extraction of all 501 pages (33-533)
  - Created test scripts for future reference: test_fullscreen_simple.py, test_high_resolution.py, test_hathitrust_zoom.py, test_narrow_window.py
  - Updated hirsch_screenshot_automation.py with loading detection and retry logic
- **Outcome**: All 501 pages successfully extracted with zero failures. Loading screen detection working (retry triggered when needed). Average file size ~440KB per page (good quality for OCR). Total extraction time ~29 minutes. Screenshots saved to `data/hirsch_images/`. Ready for OCR processing in next session. Test scripts documented resolution enhancement attempts for future reference.

## Session 75 Summary

- **Goal**: Explore alternative approaches to Hirsch commentary extraction after German Fraktur OCR termination. Discover and evaluate English translation availability.
- **Activity**:
  - Researched HathiTrust Data API and access restrictions for Google-digitized volumes
  - Discovered English translation of Hirsch commentary on HathiTrust (pages 33-533, 501 pages total)
  - Tested programmatic access - confirmed 403 Forbidden on automated requests (Cloudflare protection)
  - Built screenshot automation connecting to manually-opened Chrome browser via remote debugging
  - Successfully captured 6 sample pages with automated navigation and loading detection
  - Implemented smart OCR extraction with horizontal line detection to separate verse from commentary
  - Configured Tesseract for dual-language OCR (English + Hebrew)
  - Adjusted cropping margin to -5 pixels to capture all text immediately after separator line
  - Achieved excellent OCR quality: ~95% English accuracy, Hebrew preserved as Unicode characters
  - Created comprehensive automation guide and documentation
- **Outcome**: Complete Hirsch extraction pipeline built and validated. English translation approach vastly superior to German Fraktur (95% vs. 90% accuracy, Hebrew preserved vs. destroyed). 6 sample pages successfully extracted with reproducible results. Pipeline ready for full 501-page extraction after user tests full screen mode. Scripts created: `hirsch_screenshot_automation.py`, `hirsch_screenshot_automation_fullscreen.py`, `test_fullscreen_simple.py`, `extract_hirsch_commentary_ocr.py`. User wants to test full screen mode before proceeding with full extraction.

## Session 74 Summary

- **Goal**: Evaluate real-world OCR quality using ground truth comparison to determine if Hirsch commentary extraction is viable.
- **Activity**:
  - Ran region-based OCR on page 23 (first commentary page - Psalm 1:1)
  - Compared OCR output against ground truth text provided by user for pages 23 and 36
  - Analyzed error frequency, types, and semantic impact
  - Assessed LLM correction feasibility
  - Documented comprehensive error analysis with examples
  - Made termination decision based on empirical evidence
- **Outcome**: Hirsch OCR project terminated. Despite 81-82% confidence scores, actual text quality has ~1 severe error per 10-15 words, including garbled terminology, missing words, corrupted Hebrew (nikud lost), and unintelligible passages. Errors too severe/frequent for reliable LLM correction. All code (~5,000 lines) archived for potential future use with improved OCR technology. Comprehensive decision documentation added to IMPLEMENTATION_LOG.md.

## Session 73 Summary

- **Goal**: Implement region-based OCR to eliminate cross-contamination and achieve 75-80% confidence target.
- **Activity**:
  - Implemented `detect_text_regions_with_language()` in layout_analyzer.py (110 lines)
    - Multi-pass approach: detect Hebrew regions, then German regions separately
    - Deduplication logic to remove overlapping regions (keep higher confidence)
  - Implemented `extract_text_region_based()` in tesseract_ocr.py (200 lines)
    - Groups regions by language, applies appropriate OCR to each
    - Includes confidence tracking compatible with test framework
  - Implemented `_reconstruct_text_spatially()` helper (73 lines)
    - Spatial reconstruction with language markers
    - Line grouping and horizontal ordering within lines
  - Updated test_ocr_sample.py to use region-based approach
  - Tested on pages 36-37 with 3 iterative refinements:
    - Iteration 1: Combined `heb+deu_frak` detection ‚Üí 37.23% (confused Tesseract)
    - Iteration 2: Added missing confidence fields ‚Üí fixed test compatibility
    - Iteration 3: Multi-pass detection with deduplication ‚Üí **81.72% confidence** ‚úÖ
  - Validated text quality: Hebrew and German both extracted correctly
- **Outcome**: Target exceeded! Achieved 81.72% confidence (vs. 75-80% target, 58.3% baseline). Both Hebrew and German extracted with proper separation. Quality assessment: "Good - suitable for production use with post-processing." Ready for full commentary extraction pending user decision.

## Session 72 Summary

- **Goal**: Test multi-language OCR on Hirsch commentary and diagnose quality issues.
- **Activity**:
  - Confirmed Poppler successfully installed and working (user installed between sessions)
  - Analyzed OCR test results from pages 36-37:
    - German-only OCR: 78.4% confidence (good for German, destroys Hebrew)
    - Multi-language OCR (naive): 58.3% confidence (cross-contamination issues)
  - Implemented language detection infrastructure:
    - Added `detect_language(text)` function to layout_analyzer.py (Hebrew/German detection via Unicode ranges)
    - Added `detect_language_from_image(image)` function for image-based detection
    - Created `extract_text_multilanguage()` in tesseract_ocr.py for dual-language processing
    - Updated test_ocr_sample.py to use multi-language approach
  - Diagnosed root cause: Naive approach runs both Hebrew and German OCR on entire page, causing each language pack to produce garbage when encountering the other language
  - Designed region-based OCR solution:
    - Architecture: Detect text regions ‚Üí Identify language per region ‚Üí Apply appropriate OCR ‚Üí Reconstruct spatially
    - Created detailed 5-step implementation plan with complete code examples
    - Expected improvement: 58.3% ‚Üí 75-80% confidence
    - Estimated implementation time: 60 minutes
  - Updated documentation files for Session 73 handoff
- **Outcome**: Multi-language OCR infrastructure in place but quality insufficient (58.3%). Root cause identified and solution designed. Ready for region-based OCR implementation in Session 73.

---

## Session 71 Summary

- **Goal**: Install and configure Tesseract OCR with German Fraktur language pack to enable testing of the Hirsch OCR pipeline.
- **Activity**:
  - Installed Tesseract v5.5.0 for Windows with hardware acceleration (AVX2, AVX, FMA, SSE4.1)
  - Downloaded and configured deu_frak.traineddata language pack (1.98 MB)
  - Moved language pack to correct location: `C:\Program Files\Tesseract-OCR\tessdata\`
  - Verified all Python OCR dependencies (pdf2image, pytesseract, opencv-python, Pillow, numpy)
  - Tested Python-Tesseract integration: 161 language packs available, deu_frak confirmed
  - Attempted OCR test on sample pages - discovered Poppler dependency requirement
  - Updated TESSERACT_INSTALLATION.md with complete two-part guide (Tesseract + Poppler)
  - Updated NEXT_SESSION_PROMPT.md with Session 72 handoff and clear next steps
  - Updated IMPLEMENTATION_LOG.md with detailed Session 71 entry
- **Outcome**: Tesseract successfully installed and configured. OCR testing blocked on Poppler installation. Next steps: install Poppler utilities, verify with `pdftoppm -v`, restart terminal, run OCR test on pages 36-37.

---

## Session 70 Summary

- **Goal**: Implement complete Hirsch OCR extraction pipeline and integrate with research assembler using agentic approach.
- **Activity**:
  - Installed Python dependencies: pdf2image, pytesseract, opencv-python, Pillow, numpy
  - Created OCR module (src/ocr/): pdf_extractor.py (214 lines), preprocessor.py (353 lines), layout_analyzer.py (382 lines), tesseract_ocr.py (412 lines)
  - Created parsers module (src/parsers/): hirsch_parser.py (446 lines), verse_detector.py (403 lines), reference_extractor.py (473 lines)
  - Created 4 extraction scripts (scripts/): extract_hirsch_pdf.py (715 lines), test_ocr_sample.py (455 lines), validate_ocr_output.py (538 lines), generate_hirsch_json.py (535 lines)
  - Created HirschLibrarian agent class (src/agents/hirsch_librarian.py)
  - Integrated HirschLibrarian into ResearchAssembler
  - Total: ~5,000 lines of production-ready code with comprehensive documentation, error handling, logging, and standalone testing capabilities
  - All modules follow exact specifications from HIRSCH_OCR_RESEARCH.md
- **Outcome**: Implementation complete and ready for testing. Awaiting Tesseract OCR installation (manual step) before OCR extraction can begin. Next steps: install Tesseract with deu_frak, test on sample pages 36-37, evaluate accuracy, make go/no-go decision.

---

## Session 69 Summary

- **Goal**: Research programmatic OCR extraction of R. Samson Raphael Hirsch's German commentary from scanned PDF with Gothic (Fraktur) typeface.
- **Activity**:
  - Analyzed source PDF structure and layout (65.7MB, two-column, mixed Hebrew/German)
  - Researched 4 OCR solutions for Gothic German text: Tesseract (deu_frak), Kraken, Calamari/OCR4all, eScriptorium
  - Examined existing librarian patterns to understand integration requirements
  - Designed comprehensive 5-phase implementation pipeline with code examples
  - Created 13,500+ word research document covering: OCR technology comparison, preprocessing strategies, parsing algorithms, data structures, quality control, timeline estimates (MVP: 1 week, full: 2-3 weeks), cost-benefit analysis
  - Provided decision framework with recommended next steps: extract 5 sample pages, test Tesseract OCR, evaluate accuracy
- **Outcome**: Research phase complete with actionable implementation plan. Document saved to `docs/HIRSCH_OCR_RESEARCH.md`. Awaiting user decision on whether to proceed with implementation.

---

## Session 68 Summary

- **Goal**: Remove footnote indicators from English psalm text and integrate Rabbi Sacks commentary data into research bundles.
- **Activity**:
  - Enhanced `strip_sefaria_footnotes()` function to handle simple text-based footnote markers (e.g., "-a", "-b", "-c")
  - Created new `SacksLibrarian` class (`src/agents/sacks_librarian.py`) to load and format Rabbi Sacks references
  - Integrated SacksLibrarian into `ResearchAssembler` - automatically includes Sacks data for every psalm
  - Added `sacks_references` and `sacks_markdown` fields to `ResearchBundle` dataclass
  - Updated research bundle markdown generation to include Sacks section
  - Tested integration: Psalm 1 returns 5 Sacks references successfully formatted
- **Outcome**: Footnote indicators are now automatically removed from English translations. Rabbi Sacks references are now available to all commentary agents (Synthesis Writer and Master Editor) as part of the standard research bundle.

---

## Session 67 Summary

- **Goal**: Finalize the `sacks_on_psalms.json` data file by fixing bugs and cleaning data.
- **Activity**:
  - Implemented a robust regex-based approach to handle variations in both English and Hebrew citations.
  - Iteratively debugged the regex to handle specific edge cases like optional Gershayim in Hebrew numerals.
  - Reprocessed the `sacks_on_psalms.json` file, successfully generating snippets for 54 more entries.
  - Removed 24 specified entries from the JSON file based on `heVersionTitle`.
  - Assisted with adding a CLI tool directory to the user's PATH.
- **Outcome**: The `sacks_on_psalms.json` file is now ~94% complete (217 of 230 entries have snippets) and has been cleaned as per user requirements.

---

## Session 66 Summary

- **Goal**: Address multiple formatting issues and ensure analytical framework availability using agentic approach.
- **Activity**:
  - Used three Explore agents in parallel to investigate issues
  - Fixed Hebrew font in parentheses via XML-level setting (same approach as verse text)
  - Strengthened Master Editor prompt with explicit #### formatting examples
  - Added full analytical framework to research bundle (was only a placeholder note)
  - Implemented automatic hyphen-to-bullet conversion in document generator
  - Fixed bullet font matching (Aptos 12pt) and paragraph spacing
  - Ran full pipeline test - all fixes verified working
- **Outcome**: All four issues resolved. Word document now has proper formatting with bullets, correct fonts, Heading 4 subsections, and synthesis writer has access to full analytical framework.

---

## Session 65 Summary

- **Goal**: Fix liturgical section parser bug causing subsection content to be discarded.
- **Activity**:
  - User reported liturgical section appearing empty despite Session 64 marker-based fix
  - Added debug logging to save raw LLM response for analysis
  - Discovered parser was using `split("###")` which incorrectly split on `####` subsection headers
  - Rewrote `_parse_editorial_response()` in `src/agents/master_editor.py` to use regex-based section matching
  - Verified fix: liturgical section now has 1914 chars (vs. 168 before) with all subsections intact
- **Outcome**: Parser now correctly preserves all content including Heading 4 subsections within the liturgical section. The regex approach with line anchors ensures exact matching of section delimiters.

---

## Session 64 Summary

- **Goal**: Fix five persistent formatting and content issues using agentic approach.
- **Activity**:
  - Fixed Hebrew verse text font via XML-level setting (Aptos 12pt with all font ranges)
  - Restructured Modern Jewish Liturgical Use section with subsections (Full psalm, Key verses, Phrases)
  - Required Hebrew text alongside all transliterations
  - Fixed furtive patach transcription (vowel-before-consonant for final gutturals)
  - Debugged empty liturgical section output and implemented marker-based approach (`---LITURGICAL-SECTION-START---`)
- **Outcome**: All five fixes successfully implemented. Commentary now has proper formatting, structured liturgical section with content, and correct phonetic transcriptions.

---

## Session 63 Summary

- **Goal**: Ensure Hebrew verse text in verse-by-verse commentaries is rendered in Aptos 12pt.
- **Activity**: Multiple attempts were made to force the font and size of the Hebrew verse text in `src/utils/document_generator.py`. This included direct run-level font settings, applying a paragraph style, and an aggressive approach combining direct run settings with `cs_font` properties, while removing paragraph styles to prevent overrides.
- **Outcome**: All attempts failed to consistently apply the desired 'Aptos' 12pt font and size. The issue persists, suggesting a deeper problem with `python-docx`'s complex script font handling or environmental factors.

---

## Session 62 Summary

- **Goal**: Correctly format markdown headers in the docx output.
- **Activity**:
    - Modified `src/utils/document_generator.py` to add logic at the beginning of the `_add_paragraph_with_markdown` method. This logic now detects lines starting with `##` or `###` and converts them into `level=2` or `level=3` docx headings respectively, before processing other markdown elements.
- **Outcome**: Markdown `##` and `###` headers in the introduction content are now correctly rendered as docx headings.

---

## Session 61 Summary

- **Goal**: Ensure liturgical librarian output is correctly integrated into the research bundle.
- **Activity**:
    - Implemented `format_for_research_bundle` and `find_liturgical_usage_aggregated` methods in `src/agents/liturgical_librarian.py`.
- **Outcome**: Liturgical data is now correctly present within the `ResearchBundle` after assembly.

---

## Session 60 Summary

- **Goal**: Address various formatting and content integration issues in the generated commentary documents.
- **Activity**:
    - Fixed missing Hebrew verse text in `.docx` output.
    - Fixed incorrect `##` header formatting in `.docx`.
    - Implemented a robust fix for bidirectional parentheses rendering issues.
    - Attempted to fix Hebrew font/size in parentheses, but encountered critical document generation failures when forcing `cs_font.name`. Reverted these changes.
    - Identified that the full research bundle (`psalm_001_research_v2.md`) is missing liturgical data, which is the root cause of agents not using it.
- **Outcome**: Document generation is stable, most formatting issues resolved. Liturgical data integration and specific font issues deferred.

---

## Session 59 Summary

- **Goal**: Integrate Hebrew source text in commentary, programmatically add verse text, ensure divine names modification works.
- **Activity**:
    - Updated Master Editor and Synthesis Writer prompts to include Hebrew text when quoting sources
    - Created `_insert_verse_text_into_commentary()` method in commentary_formatter.py
    - Verified divine names modifier handles all Hebrew text additions
    - Confirmed liturgical librarian output is properly integrated in research bundles
- **Outcome**: Commentary now serves readers familiar with biblical and rabbinic Hebrew. Hebrew verse text programmatically inserted before each commentary. Divine names modification applied to all Hebrew text.

---

## Session 58 Summary

- **Goal**: Fix is_unique=0 bug, remove extra LLM calls, and simplify research bundle to minimal structure.
- **Activity**:
    - Fixed is_unique=0 filtering bug - added filter in `_group_by_psalm_phrase` to exclude phrase_match items with is_unique=0
    - Removed separate LLM validation calls - disabled `_validate_phrase_groups_with_llm` (validation now implicit in summary generation)
    - Simplified research bundle structure - removed all raw match data and metadata, bundle now contains ONLY phrase/verse + LLM summaries
    - Created `view_research_bundle.py` script to view the exact minimal bundle passed to commentary agents
    - Created `RESEARCH_BUNDLE_VIEWING_GUIDE.md` documentation
- **Outcome**: Research bundle is now minimal and clean - exactly what Master Editor and Synthesis Writer need. 14 non-unique phrases filtered out, reducing Psalm 1 from 9 to 6 phrase groups. Lower LLM costs due to removed validation calls.

---

## Session 57 Summary

- **Goal**: Fix the filtering bug and enhance LLM reasoning to correctly distinguish main prayers from supplementary material.
- **Activity**:
    - Fixed the filtering bug by wrapping Hebrew text printing in try-except blocks
    - Added explicit filtering in `generate_research_bundle` to exclude phrase groups marked as "FILTERED:"
    - Enhanced validation with heuristic pre-filter and strengthened LLM validation prompts
    - Improved LLM reasoning to correctly distinguish main prayers from supplementary material
    - Updated field labels to "Main prayer in this liturgical block"
- **Outcome**: All critical issues with Liturgical Librarian resolved. Output quality significantly improved.

---

## Session 56 Summary

- **Goal**: Stabilize the `LiturgicalLibrarian` and address user feedback on output quality.
- **Activity**:
    - Resolved a chain of `AttributeError` exceptions by implementing missing methods (`_prioritize_matches_by_type`, `_validate_summary_quality`, etc.).
    - Achieved a successful, error-free run of the test script.
    - Began addressing a new round of detailed feedback, implementing changes to grouping logic, LLM prompts, and cost-saving measures.
    - Identified a critical bug where the LLM-based filtering of false positives is not being correctly applied to the final results.
- **Outcome**: The `LiturgicalLibrarian` is more robust, but a key filtering bug persists. The project is paused pending a focused effort to resolve this bug in the next session.

---

## Session 55 Summary

- **Goal**: Debug and fix the `LiturgicalLibrarian` agent.
- **Activity**: 
    - Addressed multiple `AttributeError` exceptions by restoring missing methods (`generate_research_bundle`, `_get_db_connection`, `_prioritize_matches_by_type`, `_merge_overlapping_phrase_groups`) and correcting attribute names in the test script.
    - Due to repeated errors and file inconsistencies, the entire `src/agents/liturgical_librarian.py` file was rewritten to a known good state.
- **Outcome**: The code should now be in a stable state, ready for a full test run.