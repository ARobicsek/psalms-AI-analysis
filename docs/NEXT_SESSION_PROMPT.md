# Next Session Prompt - Phase 2c: Complete Commentary Integration

## Session Start Instructions

I'm continuing work on the Psalms AI commentary pipeline - Phase 2c: Completing Commentary Librarian Integration.

**Phase 2b (LXX + Commentary Librarian) is 85% complete** ✅

Please read these files in order:
1. `docs/CONTEXT.md` (project overview)
2. `docs/PROJECT_STATUS.md` (Phase 2b at 85%, starting Phase 2c)
3. `docs/IMPLEMENTATION_LOG.md` (scroll to **2025-10-16 - Day 7: Phase 2b**)

## Phase 2b Delivered (85% Complete ✅)

### ✅ LXX (Septuagint) Integration - 100% COMPLETE
- **Module**: `src/data_sources/sefaria_client.py` (extended with ~180 LOC)
- **Data Source**: Bolls.life API (`https://bolls.life/get-chapter/LXX/19/{chapter}/`)
- **Key Features**:
  - Automatic MT→LXX psalm numbering conversion (`get_lxx_psalm_number()`)
  - Added `lxx: Optional[str]` field to `Verse` dataclass
  - Auto-fetches Greek text for all verses (default: `include_lxx=True`)
  - Handles edge cases: Psalms 9-10 (combined), 116 (split), 146-147 (combined)
- **Testing**: Psalms 23 and 27 fully tested with LXX text
- **Result**: Every verse now includes Hebrew (MT), English, and Greek (LXX)

### ✅ Commentary Librarian Agent - 100% COMPLETE
- **Module**: `src/agents/commentary_librarian.py` (~380 LOC)
- **Commentators**: Rashi, Ibn Ezra, Radak, Metzudat David
- **Data Source**: Sefaria API (`/api/texts/{commentator}_on_Psalms.{chapter}.{verse}`)
- **Key Features**:
  - Selective fetching (2-5 key verses per psalm, not all verses)
  - Multiple commentators with graceful degradation (fetch what's available)
  - Clean HTML handling, proper UTF-8 encoding
  - Markdown output for LLM consumption
- **Testing**: Psalm 27 with 11 commentaries on 3 key verses
- **Result**: Traditional Jewish scholarship available for Scholar-Writer agents

### ✅ Scholar-Researcher Integration - 100% COMPLETE
- **Module**: `src/agents/scholar_researcher.py` (extended)
- **Changes**:
  - Added Section 4 to prompt: `commentary_requests` (optional field)
  - Updated `ScholarResearchRequest` dataclass with `commentary_requests` field
  - Extended `to_research_request()` to convert commentary requests to standard format
- **Testing**: Prompt successfully generates commentary requests for key verses
- **Result**: Scholar-Researcher can now identify which verses need traditional commentary

### ⏳ Research Assembler Integration - PENDING (15% remaining)

**What's Done**:
- Commentary Librarian fully functional as standalone module
- Commentary requests can be generated by Scholar-Researcher
- Data structures exist for commentary bundles

**What Needs Doing** (THIS SESSION):
1. Add `CommentaryLibrarian` to `ResearchAssembler.__init__()`
2. Import `CommentaryLibrarian` and `CommentaryBundle` in research_assembler.py
3. Process `commentary_requests` in `ResearchAssembler.assemble()` method
4. Add `commentary_bundles` field to `ResearchBundle` dataclass
5. Add commentary section to `ResearchBundle.to_markdown()` output
6. Add commentary count to summary statistics
7. Test full pipeline: Scholar-Researcher → Commentary Librarian → Research Bundle

## Phase 2c: Complete Commentary Integration (THIS SESSION)

### Task 1: Update Research Assembler Imports and Initialization

**File**: `src/agents/research_assembler.py`

**Steps**:
1. Add import for Commentary Librarian:
   ```python
   from .commentary_librarian import CommentaryLibrarian, CommentaryBundle
   ```

2. Add to `ResearchAssembler.__init__()`:
   ```python
   def __init__(self):
       self.bdb_librarian = BDBLibrarian()
       self.concordance_librarian = ConcordanceLibrarian()
       self.figurative_librarian = FigurativeLibrarian()
       self.commentary_librarian = CommentaryLibrarian()  # ADD THIS
   ```

### Task 2: Add Commentary Bundles to ResearchBundle Dataclass

**File**: `src/agents/research_assembler.py`

**Add field** to `ResearchBundle` dataclass:
```python
@dataclass
class ResearchBundle:
    psalm_chapter: int
    lexicon_bundles: List[LexiconBundle]
    concordance_bundles: List[ConcordanceBundle]
    figurative_bundles: List[FigurativeBundle]
    commentary_bundles: List[CommentaryBundle] = None  # ADD THIS (optional)
```

**Update `to_dict()` method** to include commentaries:
```python
def to_dict(self) -> Dict[str, Any]:
    return {
        "psalm_chapter": self.psalm_chapter,
        "lexicon": [b.to_dict() for b in self.lexicon_bundles],
        "concordance": [b.to_dict() for b in self.concordance_bundles],
        "figurative": [b.to_dict() for b in self.figurative_bundles],
        "commentary": [b.to_dict() for b in self.commentary_bundles] if self.commentary_bundles else []  # ADD THIS
    }
```

### Task 3: Process Commentary Requests in assemble() Method

**File**: `src/agents/research_assembler.py`

**Add to `ResearchAssembler.assemble()` method** (after figurative processing):
```python
# Process commentary requests
commentary_bundles = []
if hasattr(request, 'commentary_requests') and request.commentary_requests:
    commentary_requests = [
        {
            'psalm': req.get('psalm', request.psalm_chapter),
            'verse': req.get('verse'),
            'reason': req.get('reason', 'Requested by Scholar-Researcher')
        }
        for req in request.commentary_requests
        if req.get('verse')
    ]

    if commentary_requests:
        commentary_bundles = self.commentary_librarian.process_requests(
            commentary_requests,
            commentators=['Rashi']  # Default: Rashi only for efficiency
        )

# Add commentary_bundles to ResearchBundle initialization
return ResearchBundle(
    psalm_chapter=request.psalm_chapter,
    lexicon_bundles=lexicon_bundles,
    concordance_bundles=concordance_bundles,
    figurative_bundles=figurative_bundles,
    commentary_bundles=commentary_bundles  # ADD THIS
)
```

### Task 4: Add Commentary Section to Markdown Output

**File**: `src/agents/research_assembler.py`

**Add to `ResearchBundle.to_markdown()` method** (after figurative section, before summary):
```python
# Traditional Commentaries section
if self.commentary_bundles:
    md += "## Traditional Commentaries\n\n"
    md += "The following commentaries provide classical Jewish interpretations "
    md += "of verses identified as significant by the Scholar-Researcher.\n\n"

    for bundle in self.commentary_bundles:
        md += f"### Psalms {bundle.psalm}:{bundle.verse}\n\n"
        md += f"**Reason for commentary**: {bundle.reason}\n\n"

        for comm in bundle.commentaries:
            md += f"#### {comm.commentator}\n\n"

            # Hebrew commentary (truncate if too long)
            hebrew_preview = comm.hebrew[:300] + "..." if len(comm.hebrew) > 300 else comm.hebrew
            md += f"**Hebrew**: {hebrew_preview}\n\n"

            # English translation (if available)
            if comm.english:
                english_preview = comm.english[:300] + "..." if len(comm.english) > 300 else comm.english
                md += f"**English**: {english_preview}\n\n"

            md += f"*Source: {comm.reference}*\n\n"

        md += "---\n\n"
```

### Task 5: Update Summary Statistics

**File**: `src/agents/research_assembler.py`

**Update `to_dict()` summary** to include commentary counts:
```python
'summary': {
    'lexicon_entries': len(self.lexicon_bundles),
    'concordance_searches': len(self.concordance_bundles),
    'concordance_results': sum(len(b.results) for b in self.concordance_bundles),
    'figurative_searches': len(self.figurative_bundles),
    'figurative_instances': sum(len(b.instances) for b in self.figurative_bundles),
    'commentary_verses': len(self.commentary_bundles) if self.commentary_bundles else 0,  # ADD THIS
    'commentary_entries': sum(len(b.commentaries) for b in self.commentary_bundles) if self.commentary_bundles else 0  # ADD THIS
}
```

**Update markdown summary section**:
```python
md += "## Research Summary\n\n"
md += f"- **Lexicon entries**: {summary['lexicon_entries']}\n"
md += f"- **Concordance searches**: {summary['concordance_searches']}\n"
md += f"- **Concordance results**: {summary['concordance_results']}\n"
md += f"- **Figurative language searches**: {summary['figurative_searches']}\n"
md += f"- **Figurative instances found**: {summary['figurative_instances']}\n"
md += f"- **Commentary verses**: {summary['commentary_verses']}\n"  # ADD THIS
md += f"- **Commentary entries**: {summary['commentary_entries']}\n"  # ADD THIS
```

### Task 6: End-to-End Integration Testing

**Test File**: Create `test_commentary_integration.py` or test manually

**Test Plan**:
1. Create a mock Scholar-Researcher output with commentary requests
2. Pass to Research Assembler
3. Verify Commentary Librarian is called
4. Verify commentary bundles are populated
5. Verify markdown output includes commentary section
6. Verify summary statistics include commentary counts

**Sample Test Code**:
```python
from src.agents.research_assembler import ResearchAssembler, ResearchRequest

# Create test request with commentary
request_data = {
    'psalm_chapter': 27,
    'lexicon': [],
    'concordance': [],
    'figurative': [],
    'commentary': [
        {'psalm': 27, 'verse': 1, 'reason': 'Light as salvation metaphor'},
        {'psalm': 27, 'verse': 4, 'reason': 'Rare term beauty of the LORD'}
    ]
}

assembler = ResearchAssembler()
bundle = assembler.assemble_from_dict(request_data)

print("Commentary bundles:", len(bundle.commentary_bundles))
print("Total commentaries:", sum(len(b.commentaries) for b in bundle.commentary_bundles))
print("\nMarkdown output:\n")
print(bundle.to_markdown())
```

**Expected Results**:
- Commentary bundles populated with 2 verses
- 6-8 total commentary entries (3-4 commentators per verse)
- Markdown output includes "Traditional Commentaries" section
- Summary shows: `commentary_verses: 2`, `commentary_entries: 6-8`

### Task 7: Test with Real Scholar-Researcher Output

**Integration Test**:
1. Generate research request using Scholar-Researcher for Psalm 27
2. Ensure it includes `commentary_requests` field
3. Pass to Research Assembler
4. Verify full research bundle includes all 4 types of data:
   - Lexicon entries (BDB)
   - Concordance results
   - Figurative language instances
   - Traditional commentaries
5. Inspect markdown output - should be comprehensive research document

**Validation**:
- All sections present in markdown
- Commentary section appears after figurative language, before summary
- Hebrew and Greek text properly encoded
- No errors during processing

## Success Criteria

By end of this session:
1. ✅ Commentary Librarian fully integrated with Research Assembler
2. ✅ Research bundles include commentary data when requested
3. ✅ Markdown output has well-formatted commentary section
4. ✅ Summary statistics include commentary counts
5. ✅ Full pipeline tested: Scholar-Researcher → All Librarians → Complete Research Bundle
6. ✅ Documentation updated (IMPLEMENTATION_LOG.md, PROJECT_STATUS.md)
7. ✅ Git commit with Phase 2b/2c completion

## Files to Modify

**Primary**:
- `src/agents/research_assembler.py` (add commentary integration, ~100 LOC additions)

**Testing**:
- Manual test with Psalm 27
- Optional: Create `test_commentary_integration.py`

**Documentation**:
- `docs/IMPLEMENTATION_LOG.md` (add Day 7 completion notes)
- `docs/PROJECT_STATUS.md` (mark Phase 2b/2c as 100% complete)

## Expected Time

**Estimated**: 45-60 minutes
- Commentary integration: 30 minutes
- Testing and debugging: 15 minutes
- Documentation: 15 minutes

## After This Session

**Phase 2 will be ~60% complete**:
- ✅ Scholar-Researcher Agent (Day 6)
- ✅ LXX Integration (Day 7)
- ✅ Commentary Librarian (Day 7)
- ✅ Research Assembler Integration (Day 7/8)
- ⏳ RAG Documents (Day 8-9) - Next priority

**Then**: Phase 3 - Scholar-Writer Agents (Macro, Micro, Synthesis)

## Ready to Begin

When ready, start with:
1. Review `src/agents/research_assembler.py` structure
2. Add Commentary Librarian imports and initialization
3. Extend ResearchBundle dataclass
4. Add commentary processing to assemble() method
5. Test with Psalm 27

**Current Status**: Phase 2c ready to begin! 🚀

**Key Context**:
- Commentary Librarian module is complete and tested
- Scholar-Researcher can generate commentary requests
- Just need to wire them together in Research Assembler
- This is the final piece before RAG documents and Scholar-Writer agents

**Cost So Far**: ~$0.05 (Haiku requests for testing)
**Next Phase**: Scholar-Writer agents will use Sonnet 4.5 (higher cost but better analysis)
