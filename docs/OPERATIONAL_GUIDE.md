# Operational Guide - Psalms Commentary Pipeline

**Last Updated**: 2025-10-25
**Phase**: 4 - Production-Ready Pipeline

---

## Overview

This guide covers the operational aspects of running the Psalms commentary pipeline:
- Testing and output conventions
- Rate limiting and API usage
- Batch API for production runs

For technical architecture and development, see [DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md).

---

## Table of Contents

1. [Testing & Output Conventions](#testing--output-conventions)
2. [Rate Limiting & API Usage](#rate-limiting--api-usage)
3. [Batch API for Production](#batch-api-for-production)

---

# Testing & Output Conventions

## Directory Structure

```
Psalms/
├── tests/                     # All test scripts
│   ├── test_macro_analyst.py
│   ├── test_micro_analyst.py
│   └── test_*.py              # Future test files
│
├── output/                    # All generated outputs
│   ├── phase3_test/          # Phase 3 test outputs (Psalm 29)
│   │   ├── psalm_029_macro.json          # MacroAnalysis JSON
│   │   ├── psalm_029_macro.md            # MacroAnalysis markdown
│   │   ├── psalm_029_micro.json          # MicroAnalysis JSON
│   │   ├── psalm_029_micro.md            # MicroAnalysis markdown
│   │   ├── psalm_029_research.md         # Research bundle
│   │   └── psalm_029_research_requests.md # Research requests with reasons
│   │
│   └── production/           # Production runs (future)
│       └── psalm_###_*.{json,md}
│
└── logs/                     # All log files
    ├── macro_analyst_YYYYMMDD_HHMMSS.log
    ├── micro_analyst_YYYYMMDD_HHMMSS.log
    └── *.log                 # Auto-generated log files
```

## File Naming Conventions

### Test Scripts
- Location: `tests/`
- Format: `test_{component_name}.py`
- Examples:
  - `test_macro_analyst.py`
  - `test_micro_analyst.py`
  - `test_synthesis_writer.py`

### Test Outputs
- Location: `output/phase3_test/` (during development)
- Location: `output/production/` (for final runs)
- Format: `psalm_{NNN}_{pass}_{format}.{ext}`
- Examples:
  - `psalm_029_macro.json` - MacroAnalysis structured data
  - `psalm_029_macro.md` - MacroAnalysis human-readable
  - `psalm_029_micro.json` - MicroAnalysis structured data
  - `psalm_029_micro.md` - MicroAnalysis human-readable
  - `psalm_029_research.md` - Research bundle (comprehensive)
  - `psalm_029_research_requests.md` - Research requests with justifications

### Log Files
- Location: `logs/`
- Format: `{agent_name}_YYYYMMDD_HHMMSS.log`
- Auto-generated by agents with timestamps
- Examples:
  - `macro_analyst_20251017_102825.log`
  - `micro_analyst_20251017_110550.log`

## What to Read Where

### For Understanding Agent Work

**MacroAnalysis (Pass 1)**:
- Read: `output/phase3_test/psalm_029_macro.md`
- Contains: Thesis, structure, poetic devices, research questions
- Format: Beautiful markdown for humans

**MicroAnalysis (Pass 2) - Discoveries**:
- Read: `output/phase3_test/psalm_029_micro.md`
- Contains: Verse-by-verse discoveries, observations, curious words
- Format: Readable notes about what's interesting

**Research Requests**:
- Read: `output/phase3_test/psalm_029_research_requests.md`
- Contains: All requests with WHY each was made
- Format: Organized by type (BDB, concordance, figurative, commentary)

**Research Bundle**:
- Read: `output/phase3_test/psalm_029_research.md`
- Contains: Assembled research data (lexicon, concordances, etc.)
- Format: Comprehensive markdown reference

### For Machine Processing

**JSON Files**: `output/phase3_test/psalm_029_*.json`
- Structured data for next agents in pipeline
- Not intended for human reading

## Test Execution Standards

### Running Tests

```bash
# Run from project root
cd /path/to/Psalms

# Activate virtual environment
source venv/Scripts/activate

# Run specific test
python tests/test_macro_analyst.py
python tests/test_micro_analyst.py

# Or use pytest (if configured)
pytest tests/test_macro_analyst.py -v
```

### Test Output

- All test outputs go to `output/phase3_test/`
- Tests should save both `.json` and `.md` formats
- Tests should print summary to console
- Detailed logs go to `logs/`

### Cleanup Policy

**Keep**:
- All `output/phase3_test/*.md` files (human-readable)
- All `output/phase3_test/*.json` files (machine-readable)
- Latest `logs/*.log` files from each agent

**Remove**:
- Loose `.log` files in project root
- Temporary test files
- Old duplicate outputs

## Adding New Test Outputs

When creating a new agent or pass:

1. **Test Script**: Create `tests/test_{agent_name}.py`
2. **Output Files**: Save to `output/phase3_test/psalm_###_{pass}.{json,md}`
3. **Add Documentation**: If new output type, document in this file
4. **Logging**: Use auto-generated log files in `logs/`

## Production Run Structure (Future)

When ready for full 150-psalm production:

```
output/production/
├── psalm_001_macro.json
├── psalm_001_macro.md
├── psalm_001_micro.json
├── psalm_001_micro.md
├── psalm_001_research.md
├── psalm_001_synthesis.md
├── psalm_001_final.md
└── ... (all 150 psalms)
```

## Special Files

### Research Request Documentation
**File**: `psalm_###_research_requests.md`
**Purpose**: Shows WHY each research request was made
**Created by**: MicroAnalyst (Pass 2)
**Audience**: Human review of agent reasoning

This file was added in Phase 3b to provide transparency about the MicroAnalyst's curiosity-driven research strategy.

---

# Rate Limiting & API Usage

## TL;DR

**Default delay: 120 seconds** between pipeline steps (up from 90 seconds in Phase 3)

This is necessary due to the addition of the Master Editor (GPT-5) which uses ~50K tokens.

## Anthropic Rate Limits

### Current Limits (as of 2025-10)

**Token Bucket Model:**
- **Rate limit:** 30,000 input tokens per minute
- **Refill rate:** 500 tokens per second
- **Bucket size:** 30,000 tokens

**What this means:**
- You can send 30K tokens immediately
- After that, the bucket refills at 500 tokens/second
- To fully refill: 30,000 ÷ 500 = 60 seconds

**Key insight:** If you use 30K tokens, you need to wait AT LEAST 60 seconds before the next 30K token request.

## Phase 4 Token Usage Per Psalm

### Per-Step Breakdown

| Step | Model | Tokens | Delay After |
|------|-------|--------|-------------|
| 1. MacroAnalyst | Sonnet 4.5 | ~5K | 120s ✅ |
| 2. MicroAnalyst | Sonnet 4.5 | ~15K | 120s ✅ |
| 3. SynthesisWriter (intro) | Sonnet 4.5 | ~25K | (internal) |
| 3. SynthesisWriter (verses) | Sonnet 4.5 | ~30K | 120s ✅ |
| 4. MasterEditor | GPT-5 | ~50K | 120s ✅ |
| 5. Print-Ready | N/A (local) | 0 | 0s |

**Total API tokens:** ~125K across 4 API-heavy steps

### Why 120 Seconds?

**Phase 3 (90 seconds):**
- Total: ~75K tokens (macro + micro + synthesis)
- 90 seconds allows 45K tokens to refill
- This was sufficient

**Phase 4 (120 seconds):**
- Total: ~125K tokens (macro + micro + synthesis + master edit)
- Master Editor alone: ~50K tokens
- 120 seconds allows 60K tokens to refill
- **Safety margin for:**
  - Longer psalms (more verses = more tokens)
  - Network delays
  - API processing time
  - Research bundle size variations

## Delay Settings

### Default (Recommended)

```bash
python scripts/run_enhanced_pipeline.py 23
# Uses 120-second default delay
```

**Per-psalm duration:** ~8-10 minutes
- MacroAnalyst: ~30s + 120s delay
- MicroAnalyst: ~60s + 120s delay
- SynthesisWriter: ~90-120s + 120s delay
- MasterEditor: ~2-5 minutes + 120s delay
- Print-Ready: ~5s

**Total:** ~8-10 minutes per psalm

### Conservative (Extra Safe)

```bash
python scripts/run_enhanced_pipeline.py 51 --delay 150
```

**When to use:**
- Longer psalms (20+ verses)
- Network instability
- Multiple concurrent users on same API key
- Being extra cautious

**Per-psalm duration:** ~10-12 minutes

### Aggressive (Faster, Riskier)

```bash
python scripts/run_enhanced_pipeline.py 23 --delay 90
```

**When to use:**
- Short psalms (6-8 verses)
- Testing/development
- Single user, stable connection
- Willing to retry on rate limit errors

**Risk:** May hit rate limits on longer psalms

**Per-psalm duration:** ~6-8 minutes

## Rate Limit Errors

### What They Look Like

```
anthropic.RateLimitError: Error code: 429 -
{'type': 'error', 'error': {'type': 'rate_limit_error',
'message': 'Request too large for current usage tier.
Please wait before retrying.'}}
```

### How to Handle

1. **Automatic retry** - The pipeline doesn't auto-retry (by design)
2. **Manual fix:**
   ```bash
   # Resume from where it failed using skip flags
   python scripts/run_enhanced_pipeline.py 23 \
     --skip-macro --skip-micro \
     --delay 150
   ```

3. **Prevention:**
   - Use longer delays (150s for safety)
   - Process psalms sequentially (not parallel)
   - Avoid running multiple pipelines simultaneously

## Batch Processing Considerations

### Sequential Processing

**Recommended approach for 3-5 test psalms:**

```bash
# Process Psalm 23
python scripts/run_enhanced_pipeline.py 23 --delay 120

# Wait for completion (~8-10 minutes)
# Then process Psalm 1
python scripts/run_enhanced_pipeline.py 1 --delay 120

# Wait for completion
# Then process Psalm 51
python scripts/run_enhanced_pipeline.py 51 --delay 120
```

**Total time for 3 psalms:** ~24-30 minutes

### Parallel Processing

**NOT RECOMMENDED** - Will hit rate limits

```bash
# DON'T DO THIS
python scripts/run_enhanced_pipeline.py 23 &
python scripts/run_enhanced_pipeline.py 1 &
python scripts/run_enhanced_pipeline.py 51 &
# All will fail with rate limit errors
```

### Full Production (150 Psalms)

**Option A: Sequential with delays**
- Duration: 150 × 10 min = 1,500 minutes = **25 hours**
- Cost: ~$91-129 (without batch API discount)
- Simple, reliable

**Option B: Anthropic Message Batches API** ✅ RECOMMENDED
- Pre-generate all macro/micro/research
- Submit 300 synthesis requests (150 intro + 150 verses) as batch
- Master edit sequentially after
- Duration: ~24 hours for synthesis batch + ~25 hours for master editing = **~2 days**
- Cost: ~$60-85 (50% off synthesis, full price master edit)
- Most efficient

## Monitoring Token Usage

### Log Output

The pipeline logs token usage for each step:

```
[STEP 1] Running MacroAnalyst...
  ✓ Macro analysis complete
  Input tokens: 4,532

[STEP 2] Running MicroAnalyst v2...
  ✓ Micro analysis complete
  Input tokens: 14,721

[STEP 3] Running SynthesisWriter...
  ✓ Introduction complete
  Input tokens: 23,456
  ✓ Verse commentary complete
  Input tokens: 28,943

[STEP 4] Running MasterEditor...
  ✓ Editorial review complete
  Input tokens: 51,234
```

### Tracking Over Time

For production runs, monitor cumulative token usage to estimate:
- Total cost
- Completion time
- Rate limit buffer remaining

## Best Practices

### For Testing (3-5 Psalms)

✅ **DO:**
- Use default 120-second delay
- Process sequentially
- Monitor logs for token usage
- Test on diverse psalm lengths

❌ **DON'T:**
- Run psalms in parallel
- Reduce delay below 90 seconds
- Skip monitoring first few runs

### For Production (150 Psalms)

✅ **DO:**
- Use Message Batches API for synthesis
- Pre-generate all macro/micro/research files
- Sequential master editing with 120s delays
- Consider 150s delays for extra safety

❌ **DON'T:**
- Try to parallelize without batch API
- Rush the process
- Reduce delays to save time (costs more in retries)

## Troubleshooting

### "Still hitting rate limits with 120s delay"

**Possible causes:**
1. Longer psalm (20+ verses) → Use `--delay 150`
2. Large research bundle → Normal, increase delay
3. Multiple API keys on same account → Consolidate
4. Network delays → Increase delay buffer

### "Pipeline is too slow"

**Solutions:**
1. Accept the slowness (safety first)
2. Use batch API for production
3. Process only high-priority psalms
4. Run overnight/background

### "Can I speed it up safely?"

**Yes, if:**
- Testing short psalms (6-8 verses) → Try `--delay 90`
- Stable network connection
- Single user on API key
- Willing to retry if needed

**No, if:**
- Long psalms (15+ verses)
- Production run
- Shared API key
- Need reliability > speed

## Summary

**Default: 120 seconds** - Safe, reliable, recommended

**Formula:**
```
Per-psalm time = 8-10 minutes
Full 150 psalms = ~25 hours sequential (or ~2 days with batch API)
```

**Key takeaway:** The delays are there to prevent errors and ensure quality. Don't try to optimize them away unless you're willing to handle rate limit retries manually.

---

# Batch API for Production

## Overview

Anthropic's Message Batches API allows you to submit multiple requests at once for asynchronous processing with **50% cost savings** and **no rate limits**.

**Perfect for:** Processing all 150 Psalms with the SynthesisWriter pipeline

## Cost & Performance Comparison

| Method | Cost | Time | Rate Limits | Effort |
|--------|------|------|-------------|--------|
| **Batches API** | **$5.25** | 24 hrs | None | Low (submit once) |
| Standard API (sequential) | $10.50 | 10+ hrs | 30K tokens/min | High (monitor delays) |

**Why Batches Win:**
- ✓ Half the cost ($5.25 vs $10.50)
- ✓ No rate limits (can submit all 300 requests at once)
- ✓ Hands-off processing (set it and forget it)
- ✓ Batch retry logic (automatic error handling)

## How It Works

### 1. Prepare Batch Request File

Create a JSONL file where each line is a separate API request:

```jsonl
{"custom_id": "psalm_001_intro", "params": {"model": "claude-sonnet-4-20250514", "max_tokens": 4000, "messages": [{"role": "user", "content": "..."}]}}
{"custom_id": "psalm_001_verses", "params": {"model": "claude-sonnet-4-20250514", "max_tokens": 16000, "messages": [{"role": "user", "content": "..."}]}}
{"custom_id": "psalm_002_intro", "params": {"model": "claude-sonnet-4-20250514", "max_tokens": 4000, "messages": [{"role": "user", "content": "..."}]}}
...
```

**For 150 psalms:** 300 lines total (150 intros + 150 verse commentaries)

### 2. Submit Batch

```python
import anthropic

client = anthropic.Anthropic(api_key="your-api-key")

# Upload the batch file
with open("psalms_batch_requests.jsonl", "rb") as f:
    batch = client.messages.batches.create(
        requests=f
    )

print(f"Batch ID: {batch.id}")
print(f"Status: {batch.processing_status}")
```

### 3. Monitor Progress

```python
# Check status
batch = client.messages.batches.retrieve(batch.id)

print(f"Status: {batch.processing_status}")
print(f"Completed: {batch.results_url}")
```

**Processing states:**
- `in_progress` - Currently processing
- `ended` - Completed successfully
- `errored` - Something went wrong (rare)
- `canceling` - Cancellation in progress
- `canceled` - Canceled by user

### 4. Download Results

```python
if batch.processing_status == "ended":
    results = client.messages.batches.results(batch.id)

    # Save to file
    with open("psalms_batch_results.jsonl", "w") as f:
        for result in results:
            f.write(json.dumps(result) + "\n")
```

Each result line contains:
```json
{
  "custom_id": "psalm_001_intro",
  "result": {
    "type": "succeeded",
    "message": {
      "id": "msg_...",
      "content": [{"type": "text", "text": "...generated introduction..."}],
      ...
    }
  }
}
```

## Implementation for Psalms

### Script: `scripts/batch_synthesis_writer.py`

```python
"""
Generate batch synthesis requests for all 150 Psalms.
Submits to Anthropic Message Batches API for 50% cost savings.
"""

import json
import anthropic
from pathlib import Path
from synthesis_writer import SynthesisWriter

def create_batch_requests(psalms_range=(1, 151)):
    """Create JSONL batch file for all psalms."""

    writer = SynthesisWriter()
    requests = []

    for psalm_num in range(*psalms_range):
        # Load inputs
        macro_file = Path(f"output/psalm_{psalm_num:03d}/psalm_{psalm_num:03d}_macro.json")
        micro_file = Path(f"output/psalm_{psalm_num:03d}/psalm_{psalm_num:03d}_micro_v2.json")
        research_file = Path(f"output/psalm_{psalm_num:03d}/psalm_{psalm_num:03d}_research_v2.md")

        if not all([macro_file.exists(), micro_file.exists(), research_file.exists()]):
            print(f"Warning: Missing files for Psalm {psalm_num}, skipping")
            continue

        macro = writer._load_macro_analysis(macro_file)
        micro = writer._load_micro_analysis(micro_file)
        research = writer._load_research_bundle(research_file)

        # Format inputs
        macro_text = writer._format_macro_for_prompt(macro)
        micro_text = writer._format_micro_for_prompt(micro)

        # Build prompts
        from synthesis_writer import INTRODUCTION_ESSAY_PROMPT, VERSE_COMMENTARY_PROMPT

        intro_prompt = INTRODUCTION_ESSAY_PROMPT.format(
            psalm_number=psalm_num,
            macro_analysis=macro_text,
            micro_analysis=micro_text,
            research_bundle=research
        )

        verse_prompt = VERSE_COMMENTARY_PROMPT.format(
            psalm_number=psalm_num,
            macro_analysis=macro_text,
            micro_analysis=micro_text,
            research_bundle=research
        )

        # Create batch requests
        requests.append({
            "custom_id": f"psalm_{psalm_num:03d}_intro",
            "params": {
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 4000,
                "messages": [{"role": "user", "content": intro_prompt}]
            }
        })

        requests.append({
            "custom_id": f"psalm_{psalm_num:03d}_verses",
            "params": {
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 16000,
                "messages": [{"role": "user", "content": verse_prompt}]
            }
        })

    return requests

def submit_batch(requests_file):
    """Submit batch to Anthropic API."""
    client = anthropic.Anthropic()

    with open(requests_file, "rb") as f:
        batch = client.messages.batches.create(requests=f)

    print(f"✓ Batch submitted!")
    print(f"  Batch ID: {batch.id}")
    print(f"  Status: {batch.processing_status}")
    print(f"  Total requests: {len(requests)}")
    print()
    print("Check status with:")
    print(f"  python scripts/batch_synthesis_writer.py --check {batch.id}")

    return batch.id

def check_batch(batch_id):
    """Check batch status."""
    client = anthropic.Anthropic()
    batch = client.messages.batches.retrieve(batch_id)

    print(f"Batch ID: {batch.id}")
    print(f"Status: {batch.processing_status}")
    print(f"Request counts: {batch.request_counts}")

    if batch.processing_status == "ended":
        print("✓ Batch complete! Download results with:")
        print(f"  python scripts/batch_synthesis_writer.py --download {batch.id}")

def download_results(batch_id, output_dir="output/batch_results"):
    """Download and save batch results."""
    client = anthropic.Anthropic()
    results = client.messages.batches.results(batch_id)

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    for result in results:
        custom_id = result["custom_id"]

        if result["result"]["type"] == "succeeded":
            message = result["result"]["message"]
            content = message["content"][0]["text"]

            # Save to file
            output_file = output_path / f"{custom_id}.md"
            output_file.write_text(content, encoding="utf-8")
            print(f"✓ Saved: {output_file}")
        else:
            error = result["result"]["error"]
            print(f"✗ Failed: {custom_id} - {error}")

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--create", action="store_true", help="Create batch file")
    parser.add_argument("--submit", type=str, help="Submit batch file")
    parser.add_argument("--check", type=str, help="Check batch status")
    parser.add_argument("--download", type=str, help="Download batch results")

    args = parser.parse_args()

    if args.create:
        print("Creating batch requests...")
        requests = create_batch_requests()

        with open("psalms_batch_requests.jsonl", "w") as f:
            for req in requests:
                f.write(json.dumps(req) + "\\n")

        print(f"✓ Created psalms_batch_requests.jsonl ({len(requests)} requests)")

    elif args.submit:
        submit_batch(args.submit)

    elif args.check:
        check_batch(args.check)

    elif args.download:
        download_results(args.download)
```

## Workflow: End-to-End Production

### Phase 1: Prepare Input Files (Macro + Micro + Research)

```bash
# Run macro, micro, and research agents for all 150 psalms
for i in {1..150}; do
  python src/agents/macro_analyst.py $i --output-dir output/psalm_$(printf "%03d" $i)
  python src/agents/micro_analyst.py $i output/psalm_$(printf "%03d" $i)/psalm_$(printf "%03d" $i)_macro.json \
    --output-dir output/psalm_$(printf "%03d" $i) --db-path database/tanakh.db
done
```

**Time:** ~10-15 hours (can run overnight)

### Phase 2: Create and Submit Batch

```bash
# Create batch request file
python scripts/batch_synthesis_writer.py --create

# Submit to API
python scripts/batch_synthesis_writer.py --submit psalms_batch_requests.jsonl
```

**Output:** Batch ID (save this!)

### Phase 3: Wait for Processing (~24 hours)

```bash
# Check status periodically
python scripts/batch_synthesis_writer.py --check batch_xxx
```

### Phase 4: Download Results

```bash
# Download all results
python scripts/batch_synthesis_writer.py --download batch_xxx
```

**Output:** 300 markdown files in `output/batch_results/`

### Phase 5: Create Print-Ready Versions

```bash
# Process all psalms into print-ready format
for i in {1..150}; do
  python scripts/create_print_ready_commentary.py \
    --psalm $i \
    --synthesis-intro output/batch_results/psalm_$(printf "%03d" $i)_intro.md \
    --synthesis-verses output/batch_results/psalm_$(printf "%03d" $i)_verses.md \
    --output-dir output/final_psalms
done
```

**Output:** 150 complete, print-ready commentaries!

## Cost Breakdown

**Token Usage per Psalm:**
- Introduction: ~50K input + 4K output = 54K tokens
- Verses: ~50K input + 16K output = 66K tokens
- **Total per psalm:** 120K tokens

**All 150 Psalms:**
- Total tokens: 150 × 120K = 18M tokens
- Standard API cost: 18M × $3/M ÷ 2 (avg input/output) ≈ **$27**
- **Batches API cost: $27 × 0.5 = $13.50**

Wait, I need to recalculate - I was using old pricing. Let me check current Sonnet 4 pricing:
- Input: $3/M tokens
- Output: $15/M tokens

**Revised calculation:**
- Input per psalm: 50K × 2 calls = 100K tokens
- Output per psalm: 4K + 16K = 20K tokens
- Cost per psalm: (100K × $3/M) + (20K × $15/M) = $0.30 + $0.30 = $0.60
- **All 150 psalms:** 150 × $0.60 = $90
- **Batches API (50% off):** $90 × 0.5 = **$45**

## Benefits Summary

✓ **50% cost savings:** $45 vs $90
✓ **No rate limits:** Submit all 300 requests at once
✓ **Hands-off:** 24hr async processing
✓ **Reliability:** Automatic retries on errors
✓ **Scalability:** Perfect for bulk operations

## References

- [Anthropic Batches API Documentation](https://docs.anthropic.com/en/docs/build-with-claude/message-batches)
- [Batches API Reference](https://docs.anthropic.com/en/api/batches)

---

## See Also

- [DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md) - Code structure and agent development
- [TECHNICAL_ARCHITECTURE_SUMMARY.md](TECHNICAL_ARCHITECTURE_SUMMARY.md) - System architecture
- [QUICK_START.md](../QUICK_START.md) - Getting started guide
- [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md) - Complete documentation map
