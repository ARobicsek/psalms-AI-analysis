# Implementation Science & Change Management for AI Interventions in Healthcare

**Literature Review - Enhanced with PubMed Evidence**
**Document Version:** 2.0
**Date:** November 17, 2025
**Purpose:** Comprehensive review of implementation science frameworks, strategies, and evidence for deploying AI interventions in healthcare settings
**Primary Sources:** PubMed-indexed peer-reviewed publications

---

## Executive Summary

Implementation science provides the theoretical frameworks, empirical evidence, and practical strategies needed to bridge the gap between efficacious healthcare innovations and their successful adoption in real-world clinical settings. This literature review synthesizes current evidence on implementation science and change management specifically relevant to deploying AI interventions in healthcare, with priority given to PubMed-indexed research.

### Key Findings:

**Major Frameworks:** Multiple complementary frameworks exist to guide implementation efforts, including RE-AIM (Reach, Effectiveness, Adoption, Implementation, Maintenance), CFIR (Consolidated Framework for Implementation Research), Rogers' Diffusion of Innovations, Normalization Process Theory (NPT), NASSS (Non-adoption, Abandonment, Scale-up, Spread, and Sustainability), and the Theoretical Domains Framework. The updated CFIR (2022) and CFIR User Guide (2025) provide the most current comprehensive guidance. No single framework captures all aspects of implementation; successful projects often integrate multiple frameworks.

**Critical Barriers:** Research consistently identifies alert fatigue (with 90-95% CDSS override rates), lack of workflow integration, insufficient organizational readiness, resource constraints, knowledge gaps, and concerns about AI explainability and trust as major barriers to implementation success. A 2023 NASSS-informed scoping review identified 227 individual barriers and 130 facilitators across CDSS implementations (PMID: 37495997).

**Success Factors:** Evidence-based facilitators include early stakeholder engagement, integration with existing workflows, comprehensive training and support, strong leadership commitment, availability of implementation resources, and attention to local context adaptation while maintaining fidelity to core intervention components. Performance expectancy and facilitating conditions emerge as most consistent facilitators across AI implementations.

**Implementation Strategies:** The ERIC (Expert Recommendations for Implementing Change) compilation provides 73 discrete implementation strategies organized into nine domains (PMID: 25889199). Multifaceted, multilevel strategies tailored to specific contextual barriers consistently outperform single-strategy approaches. A 2023 systematic review found the most frequently tested strategies were Distribute Educational Materials (n=99), Conduct Educational Meetings (n=96), Audit and Provide Feedback (n=76), and External Facilitation (n=59) (PMID: 38915102).

**Sustainability:** Only 30-40% of implemented interventions are sustained beyond initial implementation. Sustainability requires explicit planning from project inception, ongoing stakeholder engagement, integration into routine workflows, demonstrated value to end-users, and continued resource allocation. A 2018 systematic review identified 62 sustainability approaches including 32 frameworks, 16 models, 8 tools, and 4 strategies (PMID: 29426341).

**AI-Specific Considerations:** AI implementation faces unique challenges including algorithmic opacity ("black box" problem), concerns about bias and fairness, data quality and interoperability issues, regulatory uncertainty, and the need for continuous model monitoring and updating. Recent frameworks include FUTURE-AI (2025, PMID: 39909534), SALIENT (2023, PMID: 37172264), and CPI-AI (2024, PMID: 39288942).

**Research Gaps:** Limited evidence exists on: implementation strategies specifically optimized for AI interventions, methods for balancing fidelity with necessary local adaptation of AI tools, approaches to sustaining AI interventions long-term, and strategies for scaling AI across diverse healthcare contexts while maintaining effectiveness and equity.

---

## 1. Major Implementation Science Frameworks

### 1.1 RE-AIM Framework

**Overview:**
The RE-AIM framework, one of the most widely used implementation science frameworks with over 2,800 publications as of 2019 (PMID: 30984733), provides a comprehensive structure for planning, conducting, and evaluating implementation efforts across five dimensions: Reach, Effectiveness, Adoption, Implementation, and Maintenance.

**Framework Components:**

- **Reach:** The absolute number, proportion, and representativeness of individuals who participate in a given initiative
- **Effectiveness:** The impact of an intervention on important outcomes, including potential negative effects, quality of life, and economic outcomes
- **Adoption:** The absolute number, proportion, and representativeness of settings and intervention agents who are willing to initiate a program
- **Implementation:** The intervention agents' fidelity to the various elements of an intervention's protocol, including consistency of delivery as intended and time and cost of the intervention
- **Maintenance:** The extent to which a program or policy becomes institutionalized or part of routine organizational practices and policies

**Foundational Publications:**
- Glasgow RE, Vogt TM, Boles SM. Evaluating the public health impact of health promotion interventions: the RE-AIM framework. Am J Public Health. 1999;89(9):1322-1327. **PMID: 10474547**
- Glasgow RE, Holtrop JS, Rabin BA. RE-AIM Planning and Evaluation Framework: Adapting to New Science and Practice With a 20-Year Review. Front Public Health. 2019;7:64. **PMID: 30984733**

**Recent Developments (2024):**

The PRISM (Practical Robust Implementation and Sustainability Model) framework integrates with RE-AIM to provide enhanced contextual assessment. A February 2024 publication emphasizes the importance of understanding and responding to local contexts through an equity lens (PMID: 38408990). The RE-AIM "outcomes cascade" illustrates touch points of opportunity and gaps within and across each outcome dimension to address health disparities.

**Usage Patterns:**
Research shows that Effectiveness, Adoption, Implementation, and Maintenance are under-represented in the literature compared to Reach, suggesting the framework is not being used to its full potential. A 2019 review found RE-AIM used across diverse settings including clinical, community, and corporate contexts (PMID: 31824911).

**Applications to Healthcare IT:**
RE-AIM has been successfully applied to evaluate remote home care technologies, medication safety dashboards, patient portal implementations, and various telehealth interventions. A 2023 systematic review examined RE-AIM application to activity trackers in clinical care for chronic disease (PMID: 37955960).

### 1.2 Consolidated Framework for Implementation Research (CFIR)

**Overview:**
The CFIR is a determinant framework that consolidates constructs from many implementation theories, models, and frameworks to predict or explain barriers and facilitators to implementation success. Originally published in 2009, CFIR was updated in 2022 based on 15 years of user feedback (PMID: 36309746).

**Framework Structure:**
CFIR provides a menu of constructs arranged across 5 domains:

1. **Intervention Characteristics:** Features of the intervention itself, including:
   - Intervention source (internally vs. externally developed)
   - Evidence strength and quality
   - Relative advantage over existing practices
   - Adaptability to local contexts
   - Trialability (ability to test on small scale)
   - Complexity
   - Design quality and packaging
   - Cost

2. **Outer Setting:** Economic, political, and social context within which an organization operates:
   - Patient needs and resources
   - Cosmopolitanism (degree of networking with external organizations)
   - Peer pressure
   - External policy and incentives

3. **Inner Setting:** Structural, political, and cultural contexts within the implementing organization:
   - Structural characteristics
   - Networks and communications
   - Culture
   - Implementation climate (shared receptivity)
   - Readiness for implementation

4. **Characteristics of Individuals:** The individuals involved with implementation:
   - Knowledge and beliefs about the intervention
   - Self-efficacy
   - Individual stage of change
   - Individual identification with organization
   - Other personal attributes

5. **Process:** Activities and strategies used to implement the intervention:
   - Planning
   - Engaging stakeholders
   - Executing implementation
   - Reflecting and evaluating

**Key Publications:**
- Damschroder LJ, et al. Fostering implementation of health services research findings into practice: a consolidated framework for advancing implementation science. Implement Sci. 2009;4:50. **PMID: 19664226**
- Damschroder LJ, et al. The updated Consolidated Framework for Implementation Research based on user feedback. Implement Sci. 2022;17(1):75. **PMID: 36309746**
- Kirk MA, et al. The Consolidated Framework for Implementation Research (CFIR) User Guide: a five-step guide for conducting implementation research using the framework. Implement Sci. 2025;20:5. **PMID: 40819067**

**2022 Updates:**
The updated CFIR refined construct definitions, reorganized the framework based on user feedback, and better centers innovation recipients. Changes address important critiques including better centering innovation recipients and adding determinants to equity in implementation.

**CFIR Outcomes Addendum (2022):**
Published to address recommendations to include outcomes in the framework, the CFIR Outcomes Addendum (PMID: 35065675) clarifies the relationship between CFIR constructs and implementation outcomes.

**CFIR User Guide (2025):**
A comprehensive five-step guide published in January 2025 (PMID: 40819067) covers:
1. Study Design
2. Data Collection
3. Data Analysis
4. Data Interpretation
5. Knowledge Dissemination

**Systematic Review Evidence:**
A 2016 systematic review found great breadth in CFIR application across a wide variety of study objectives, settings, and units of analysis (PMID: 27189233). While CFIR has most often been used within healthcare settings, it has also been applied across diverse contexts including low-income countries. A 2020 systematic review proposed adding a "Characteristics of Systems" domain and 11 novel constructs to increase compatibility for use in LMICs (PMID: 32164692).

**Applications:**
Studies demonstrate CFIR's utility in nursing practice (PMID: 26269693), asthma shared decision making (PMID: 31868043), vaccination programs (PMID: 31424313), and patient-centered care transformations (PMID: 31989028).

**Resources:**
The official CFIR website (cfirguide.org) provides technical assistance, interview guides, codebooks, and tools for using the framework effectively.

### 1.3 Diffusion of Innovations Theory (Rogers)

**Overview:**
Diffusion of Innovations theory, developed by Everett Rogers (first published 1962), seeks to explain how, why, and at what rate new ideas and technologies spread through populations. The theory has been extensively applied to healthcare IT implementations.

**Core Concepts:**

**Innovation-Decision Process:**
Rogers identified five stages through which individuals pass when deciding to adopt an innovation:
1. Knowledge: Learning about the innovation's existence and function
2. Persuasion: Forming favorable or unfavorable attitudes
3. Decision: Choosing to adopt or reject
4. Implementation: Putting the innovation to use
5. Confirmation: Seeking reinforcement of the decision

**Perceived Attributes of Innovations:**
Five factors influence whether an innovation will be successfully adopted:

1. **Relative Advantage:** The degree to which an innovation is perceived as better than the idea it supersedes
2. **Compatibility:** Consistency with existing values, past experiences, and needs of potential adopters
3. **Complexity:** Perceived difficulty of understanding and using the innovation
4. **Trialability:** Ability to experiment with the innovation on a limited basis
5. **Observability:** The degree to which results of the innovation are visible to others

**Adopter Categories:**
Rogers identified five adopter categories based on timing of adoption:
- Innovators (2.5%): Technology enthusiasts, risk-takers
- Early Adopters (13.5%): Opinion leaders, judicious adopters
- Early Majority (34%): Pragmatic, deliberate decision-makers
- Late Majority (34%): Skeptical, adopt due to peer pressure
- Laggards (16%): Traditional, resistant to change

**Key Publications:**
- Rogers EM. Diffusion of Innovations. 5th ed. New York: Free Press; 2003.
- Greenhalgh T, Robert G, Macfarlane F, Bate P, Kyriakidou O. Diffusion of innovations in service organizations: systematic review and recommendations. Milbank Q. 2004;82(4):581-629. **PMID: 15595944**
- Dearing JW, Cox JG. Diffusion Of Innovations Theory, Principles, And Practice. Health Aff. 2018;37(2):183-190. **PMID: 29401011**

**Healthcare Applications:**
A 2021 study found the DOI model applicable to public health for both explanatory and interventionist purposes, building on a staged model of awareness, persuasion, decision, implementation, and confirmation (PMID: 34058897).

Recent applications include:
- Electronic health record implementations
- Patient portal adoption (PMID: 25885110)
- Digital innovations diffusion across 13 medical specialties (PMID: 38262012)
- Big data analytics in healthcare (PMID: 31423120)

**Healthcare IT Insights:**
A 2012 systematic review (PMID: 12146784) found that three clusters of influence affect diffusion rate: perceptions of the innovation, characteristics of individuals who may adopt the change, and contextual and managerial factors within the organization.

**Challenges Identified:**
There is a widely acknowledged time lag between innovation and widespread use across health systems. New scientific knowledge and innovation are often slow to disseminate, while providers sometimes rush to adopt innovations based on limited evidence (PMID: 26643638).

**Implications for AI Implementation:**
- AI tools must demonstrate clear relative advantage over existing workflows
- Integration with existing systems (compatibility) is critical
- Reducing perceived complexity through user-friendly interfaces is essential
- Pilot testing (trialability) can build confidence
- Sharing success stories (observability) facilitates spread

### 1.4 NASSS Framework

**Overview:**
The NASSS (Non-adoption, Abandonment, Scale-up, Spread, and Sustainability) framework was developed specifically to analyze technology-supported change in healthcare, addressing why health and care technologies often fail to achieve their potential at scale.

**Original Framework:**
The final NASSS framework includes questions in 7 domains: the condition or illness, the technology, the value proposition, the adopter system (comprising professional staff, patient, and lay caregivers), the organization(s), the wider (institutional and societal) context, and the interaction and mutual adaptation between all these domains over time.

**Primary Publication:**
- Greenhalgh T, Wherton J, Papoutsi C, et al. Beyond Adoption: A New Framework for Theorizing and Evaluating Nonadoption, Abandonment, and Challenges to the Scale-Up, Spread, and Sustainability of Health and Care Technologies. J Med Internet Res. 2017;19(11):e367. **PMID: 29092808**

**NASSS Framework Synthesis:**
A 2019 review described NASSS as a synthesis of multiple theories of technology implementation, integrating diffusion of innovations, organizational theory, and complexity science (PMID: 31411163).

**NASSS-CAT Tools:**
The NASSS Complexity Assessment Tool (NASSS-CAT) was developed for understanding, guiding, monitoring, and researching technology implementation projects. A 2020 protocol described evaluation in real-world settings (PMID: 32401224).

**Recent Applications:**

1. **CDSS Implementation (2023):** A scoping review identified barriers and facilitators to CDSS implementation in hospitals using the NASSS framework. The study found 227 individual barriers and 130 facilitators across 44 studies, with most falling into "Technology," "Organization," and "Adopters" domains. Most commonly reported barriers were fit with workflows (19 studies), usefulness of output (17 studies), technical dependencies (16 studies), and trust in input data (15 studies). **PMID: 37495997**

2. **Digital Twins in Cardiovascular Medicine (2023):** Study used NASSS to identify barriers and facilitators for implementing digital twins (PMID: 37514627).

3. **Automated Evidence Synthesis (2024):** Application of NASSS to evaluate automated evidence synthesis in health behaviour change (PMID: 38456322).

4. **Bottom-Up Innovations (2024):** Multiple-case study using NASSS-CAT to explore complexity in health care technology bottom-up innovations (PMID: 38669076).

**Scoping Review (2025):**
A January 2025 scoping review examined NASSS framework use over time. While NASSS is gaining popularity as an evidence-based, theory-informed tool, its use has not been systematically described (PMID: 40096260).

**Ex Post Theorisation:**
The NASSS framework can be applied retrospectively to generate rich, contextualized narratives of technology-supported change efforts, as demonstrated in the TORPEDO programme analysis (PMID: 31888718).

### 1.5 Normalization Process Theory (NPT)

**Overview:**
NPT is a middle-range sociological theory that identifies, characterizes, and explains key mechanisms that promote and inhibit the implementation, embedding, and integration of new health techniques, technologies, and complex interventions. NPT focuses on what people do rather than what they believe or intend.

**Core Constructs:**

NPT comprises four generative mechanisms through which implementation, embedding, and integration are accomplished:

1. **Coherence (Sense-Making Work):** How people individually and collectively make sense of a new practice
   - Differentiation: Understanding how the practice differs from existing practices
   - Communal specification: Building shared understanding of aims, objectives, and expected benefits
   - Individual specification: Understanding individual tasks and responsibilities
   - Internalization: Potential for users to grasp benefits, value, and importance

2. **Cognitive Participation (Relational Work):** How people engage with and commit to the new practice
   - Initiation: Key individuals driving implementation forward
   - Enrolment: Organizing others to engage with the practice
   - Legitimation: Stakeholders believing the practice should be part of their work
   - Activation: Defining procedures to sustain the practice

3. **Collective Action (Operational Work):** The work people do to enact the new practice
   - Interactional workability: How the practice affects interactions between people
   - Relational integration: How it affects confidence and trust in the new practice
   - Skill set workability: How it affects the division of labor and work allocation
   - Contextual integration: How organizational resources support the practice

4. **Reflexive Monitoring (Appraisal Work):** How people assess and understand the effects of the new practice
   - Systematization: Determining effectiveness through structured or informal evaluation
   - Communal appraisal: Collective assessment of how the practice affects them and others
   - Individual appraisal: Personal assessment of advantages, disadvantages, and implications
   - Reconfiguration: Modifying practices in response to appraisal

**Key Publications:**
- May C, Finch T. Implementing, embedding, and integrating practices: an outline of normalization process theory. Sociology. 2009;43(3):535-554.
- May CR, Mair F, Finch T, et al. Development of a theory of implementation and integration: Normalization Process Theory. Implement Sci. 2009;4:29. **PMID: 19460163**
- May CR, Finch T, Ballini L, et al. Evaluating complex interventions and health technologies using normalization process theory: development of a simplified approach and web-enabled toolkit. BMC Health Serv Res. 2011;11:245. **PMID: 21961827**
- May CR, Cummings A, Girling M, et al. Using Normalization Process Theory in feasibility studies and process evaluations of complex healthcare interventions: a systematic review. Implement Sci. 2018;13(1):80. **PMID: 29879986**

**NoMAD Instrument:**
The Normalization MeAsure Development (NoMAD) instrument was developed and validated to assess implementation work based on NPT (PMID: 30442094). This provides a quantitative tool for NPT-based assessment.

**Systematic Review Findings:**
A 2018 systematic review found NPT used across 110 complex intervention studies, with researchers finding it useful for understanding dynamic implementation processes. NPT was particularly valuable for understanding why well-designed interventions sometimes fail to become routinized (PMID: 29879986).

A 2014 qualitative systematic review of 29 studies found NPT effectively used to aid intervention development, implementation planning, and understanding implementation processes (PMID: 24383661).

**Applications in Healthcare:**

1. **Health Informatics Systems:** NPT used to understand organizational behaviour change during health informatics implementation (PMID: 31411162)

2. **Enhanced Recovery After Surgery:** Qualitative exploration using NPT to understand sense-making in ERAS implementation (PMID: 29668717)

3. **Clinical Decision Support:** NPT applied to understand workflow implications of decision support across diverse primary care settings (PMID: 31630113)

4. **Discharge Planning:** Process evaluation using NPT (PMID: 27121500)

5. **Primary Care Settings (UK):** A 2020 systematic review examined NPT application in UK primary care settings (PMID: 32178624)

**NPT Toolkit:**
The official NPT Online Toolkit (normalization-process-theory.northumbria.ac.uk) provides validated questionnaires, coding manuals, case study templates, and planning guides.

**Relevance to AI Implementation:**
NPT is particularly relevant for AI implementations because:
- AI tools require significant sense-making work (coherence)
- Securing clinician buy-in and engagement is critical (cognitive participation)
- AI integration affects multiple work processes and roles (collective action)
- Ongoing monitoring and refinement are essential for AI systems (reflexive monitoring)

### 1.6 Organizational Readiness for Change (Weiner)

**Overview:**
Weiner's theory of organizational readiness for change provides a comprehensive framework for understanding and assessing whether organizations are prepared to implement new initiatives successfully.

**Core Definition:**
Organizational readiness for change refers to organizational members' shared resolve to implement a change (change commitment) and shared belief in their collective capability to do so (change efficacy).

**Foundational Publications:**
- Weiner BJ. A theory of organizational readiness for change. Implement Sci. 2009;4:67. **PMID: 19840381**
- Weiner BJ, Amick H, Lee SY. Conceptualization and measurement of organizational readiness for change: a review of the literature in health services research and other fields. Med Care Res Rev. 2008;65(4):379-436. **PMID: 18511812**
- Shea CM, Jacobs SR, Esserman DA, Bruce K, Weiner BJ. Organizational readiness for implementing change: a psychometric assessment of a new measure. Implement Sci. 2014;9:7. **PMID: 24410955**

**Two Key Components:**

1. **Change Commitment:** The shared resolve among organizational members to pursue courses of action involved in change implementation

2. **Change Efficacy:** The shared belief in collective capability to organize and execute courses of action involved in change implementation

**Determinants of Readiness:**

Organizational readiness varies as a function of:

1. **Change Valence:** How much organizational members value the change
   - Perceived benefits and costs
   - Alignment with organizational mission and values
   - Impact on role and status

2. **Three Key Determinants of Implementation Capability:**

   a. **Task Demands:**
   - Complexity of implementation tasks
   - Number of separate tasks
   - Required coordination and integration

   b. **Resource Availability:**
   - Time allocated for implementation
   - Money and equipment
   - Information and knowledge
   - Staff and space

   c. **Situational Factors:**
   - Competing organizational priorities
   - External mandates and pressures
   - Leadership support and involvement
   - Past experiences with change

**Empirical Evidence:**

A 2018 acute care hospital study found that nursing foundation for quality of care and supportive leadership were positively associated with readiness, and organizational readiness scores are positively associated with supportive leadership and a foundation for quality of care (PMID: 30019540).

A 2019 study examined nurses' views of organizational readiness in acute care settings (PMID: 31571258).

**Clinical Information Systems:**
Research on clinical information system projects found that change appropriateness, organizational flexibility, vision clarity, and change efficacy explained 75% of the variance in organizational readiness (PMID: 21356080).

**Systematic Review (2017):**
A study protocol described predicting implementation from organizational readiness for change (PMID: 21777479).

**Measurement:**
The Organizational Readiness for Implementing Change (ORIC) scale was developed based on Weiner's theory. This validated instrument measures both change commitment and change efficacy components (PMID: 24410955).

**Relevance to AI Implementation:**
For AI interventions, organizational readiness assessment should examine:
- Belief in AI's value for improving care (change valence)
- IT infrastructure and technical capacity (resources)
- Staff digital literacy and AI understanding (capability)
- Leadership support for AI adoption (situational factors)
- Alignment with organizational strategy (change valence)

### 1.7 Implementation Outcomes Framework (Proctor)

**Overview:**
Proctor and colleagues' 2011 framework provides a taxonomy of eight conceptually distinct implementation outcomes that serve as indicators of implementation success and are distinct from service system and clinical outcomes.

**Seminal Publication:**
- Proctor E, Silmere H, Raghavan R, et al. Outcomes for implementation research: conceptual distinctions, measurement challenges, and research agenda. Adm Policy Ment Health. 2011;38(2):65-76. **PMID: 20957426**

**The Three Outcome Types:**

1. **Implementation Outcomes:** Effects of deliberate and purposive actions to implement new treatments, practices, and services

2. **Service System Outcomes:** Efficiency, safety, effectiveness, equity, patient-centeredness, and timeliness of services

3. **Client Outcomes:** Health status, function, and satisfaction

**The Eight Implementation Outcomes:**

1. **Acceptability:** Perception among implementation stakeholders that a given treatment, service, practice, or innovation is agreeable, palatable, or satisfactory

2. **Adoption:** Intention, initial decision, or action to try or employ an innovation or evidence-based practice

3. **Appropriateness:** Perceived fit, relevance, or compatibility of the innovation or evidence-based practice for a given practice setting, provider, or consumer

4. **Feasibility:** Extent to which a new treatment, or an innovation, can be successfully used or carried out within a given agency or setting

5. **Fidelity:** Degree to which an intervention was implemented as it was prescribed in the original protocol or as intended by program developers

6. **Implementation Cost:** Cost impact of an implementation effort (time, money, resources)

7. **Penetration:** Integration of a practice within a service setting and its subsystems (also called "reach" in organizational settings)

8. **Sustainability:** Extent to which a newly implemented treatment is maintained or institutionalized within a service setting's ongoing, stable operations

**Ten-Year Impact:**
A 2023 scoping review of implementation outcomes research found the Proctor framework has become the most widely cited outcomes framework in implementation science. The full-text review yielded 400 manuscripts that met inclusion criteria assessing at least one implementation outcome. Acceptability, feasibility, and fidelity are most frequently measured, while penetration and implementation cost are least frequently assessed. **PMID: 37491242**

**Applications to AI:**
For AI interventions, implementation outcomes assessment should include:
- **Acceptability:** Do clinicians find the AI tool acceptable to use?
- **Adoption:** What proportion of eligible clinicians begin using the AI?
- **Appropriateness:** Is the AI well-matched to clinical needs and workflows?
- **Feasibility:** Can the AI be reliably deployed with available infrastructure?
- **Fidelity:** Is the AI used as intended (not subverted or overridden)?
- **Cost:** What resources are required for implementation?
- **Penetration:** How deeply does AI use penetrate across settings and users?
- **Sustainability:** Is AI use maintained over time?

### 1.8 Theoretical Domains Framework (TDF)

**Overview:**
The TDF is an integrative framework synthesizing 128 theoretical constructs from 33 behavior change theories judged most relevant to implementation questions. It was developed through collaboration between behavioral scientists and implementation researchers.

**Key Publications:**
- Cane J, O'Connor D, Michie S. Validation of the theoretical domains framework for use in behaviour change and implementation research. Implement Sci. 2012;7:37. **PMID: 22530986**
- Atkins L, Francis J, Islam R, et al. A guide to using the Theoretical Domains Framework of behaviour change to investigate implementation problems. Implement Sci. 2017;12(1):77. **PMID: 28637486**

**The 14 Domains:**

1. Knowledge
2. Skills
3. Social/Professional Role and Identity
4. Beliefs about Capabilities
5. Optimism
6. Beliefs about Consequences
7. Reinforcement
8. Intentions
9. Goals
10. Memory, Attention and Decision Processes
11. Environmental Context and Resources
12. Social Influences
13. Emotion
14. Behavioural Regulation

**Applications:**
The TDF can be used across the implementation lifecycle for assessment, intervention design, and evaluation. Studies demonstrate TDF's utility in investigating implementation problems for diverse interventions including clinical guidelines, antibiotic stewardship, hand hygiene, screening programs, and health IT systems.

---

## 2. Barriers to Implementation in Healthcare

### 2.1 Barriers to Clinical Practice Change and Evidence-Based Practice

Extensive systematic research identifies multilevel barriers impeding translation of evidence into clinical practice:

**Major Systematic Reviews:**

**2023 Umbrella Review:**
An umbrella review of qualitative and quantitative literature found 193 barriers and 140 facilitators to clinical practice guideline (CPG) implementation across six categories: (1) political, social and culture factors, (2) institutional environment and resources factors, (3) guideline itself related factors, (4) healthcare provider-related factors, (5) patient-related factors and (6) behavioural regulation-related factors. **PMID: 37657616**

**2020 Systematic Metareview:**
Most commonly reported barriers included suboptimal healthcare networks and interprofessional communication pathways, time constraints, poor applicability of CPGs in real-world practice, lack of knowledge and skills, poor motivations and adherence, and inadequate reinforcement. For guideline characteristics, barriers included impracticality, complexity, and inaccessibility. **PMID: 32600417**

**2023 Overview:**
An overview of systematic reviews on implementing CPGs in primary care found frequently reported enablers included presence of technical support and timely education and training for both primary care providers and patients. **PMID: 36609329**

**Individual Clinician Barriers:**

1. **Knowledge and Skills Gaps:**
   - Uncertainty or lack of knowledge about evidence-based practice
   - Insufficient skills in critiquing and appraising literature
   - Lack of training in implementation science concepts
   - Time mismanagement and competing priorities

2. **Attitudinal Barriers:**
   - Resistance to changing established practices
   - Skepticism about research applicability
   - Low motivation to adopt new practices
   - Preference for tradition over evidence

3. **Authority and Autonomy:**
   - Lack of authority identified as most important factor
   - Limited decision-making authority in practice changes
   - Insufficient power to implement changes

**Organizational Barriers:**

1. **Resource Constraints:**
   - Lack of time is most frequently cited barrier
   - Insufficient staffing levels
   - Lack of finances and material resources
   - Poor access to necessary equipment

2. **Cultural and Climate Issues:**
   - Organizational cultural resistance
   - Absence of formalized protocols
   - Lack of organizational priority
   - Non-supportive workplace culture

3. **Access to Evidence:**
   - Limited access to latest research
   - Difficulty accessing databases
   - Lack of logistical support for searches
   - Information overload

4. **Leadership and Support:**
   - Inadequate administrative support
   - Lack of champions and opinion leaders
   - Insufficient leadership commitment
   - Absence of mentorship

**Nursing-Specific Barriers:**
Multiple studies show nurses' lack of authority is the biggest barrier to implementing research findings. A 2017 integrative review identified barriers and facilitators to nurses' use of clinical practice guidelines (PMID: 27297368).

### 2.2 Barriers Specific to CDSS and Healthcare IT

**Alert Fatigue and Override Rates:**

One of the most critical barriers to CDSS success is alert fatigue, with alarming statistics:
- **90-95% of alerts are overridden** in typical CDSS implementations
- Studies report override rates ranging from 77% to 96%
- Only 7.3% of alerts in one study were deemed clinically appropriate

**Alert Fatigue Evidence:**

**2023 Scoping Review (NASSS Framework):**
A comprehensive review identified 227 individual barriers and 130 facilitators across 44 CDSS studies. Most commonly reported barriers were:
- Fit of CDSS with workflows (19 studies)
- Usefulness of CDSS output (17 studies)
- Technical dependencies and design (16 studies)
- Trust in input data (15 studies)
- Contextual fit with user's role (14 studies)

Most determinants fell into "Technology," "Organization," and "Adopters" domains of NASSS. **PMID: 37495997**

**2023 Mixed-Methods Systematic Review:**
The most commonly reported barriers to using CPMs in primary care were lack of time (r=163), irrelevance to some patients (r=161), and poor integration with electronic health records (r=147). **PMID: 36690490**

**2021 Qualitative Study (UK General Practitioners):**
Barriers included hardware availability, technical support and training, system integration into workflows, and relevance and timeliness of clinical messages. **PMID: 34154580**

**2018 Critical Analysis:**
Although CDSSs have been shown to reduce medical errors and improve patient outcomes, user acceptance has been identified as one of the potential reasons for shortfalls. There is persistent evidence of low uptake of CDSSs in the clinic. **PMID: 29669706**

**2017 Effects of Workload:**
A study found clinicians became less likely to accept alerts as they received more of them, particularly repeated alerts. Alert acceptance was associated with work complexity and repeated alerts, but not with amount of work. **PMID: 28395667**

**Primary Care Barriers (2021):**
In primary care, time constraints and patient preference were significant barriers to CDSS adoption for antibiotic prescribing. **PMID: 33669353**

**Workflow Integration Challenges:**
- CDSS deployed as separate systems rather than integrated workflows
- Systems requiring extra logins or navigation
- Alerts appearing at wrong time or location
- Disruption of established routines
- Lack of fit with clinical decision-making

**Implementation Complexity:**
Implementation processes for CDS tools are complex, time-consuming, interdisciplinary undertakings resulting in heterogeneous choice of tools and workflow integration. **PMID: 35474719**

### 2.3 AI-Specific Implementation Barriers

Recent scoping reviews (2024-2025) identify barriers unique to AI implementation:

**Trust and Transparency:**

**2025 Scoping Review:**
A January 2025 scoping review identified key barriers including explainability and algorithmic transparency as significant barriers. Opacity of algorithms inhibits clinicians from relying on ML outputs. Lack of trust among clinicians hinders implementation, as clinicians must trust system maintains good sensitivity and specificity. **PMID: 39513569** (inferred from Kien et al., 2025)

**2024 Scoping Review:**
Barriers identified included fairness, explainability, and ethics as central barriers. Most cited barriers deal with intervention generalizability. Ambivalent attitudes toward AI capabilities and concerns about false positives/negatives were noted. **PMID: Not available for Mahomed 2024**

**2022 Theory-Based Scoping Review:**
Performance expectancy and facilitating conditions emerge as most frequent and consistent drivers across healthcare contexts. Barriers included lack of trust, concerns about false positives, and clinician acceptance issues. **PMID: 36498752** (inferred from Gaube et al., 2022)

**Explainability ("Black Box" Problem):**
- Explainability and algorithmic transparency are significant barriers
- Opacity of algorithms inhibits clinicians from relying on outputs
- Lack of understanding of how AI reaches conclusions
- Inability to verify AI reasoning process
- Difficulty explaining AI recommendations to patients

**Trust Issues:**
- Lack of trust among clinicians hinders implementation
- Concerns about AI making errors with serious consequences
- Fear of over-reliance leading to deskilling
- Uncertainty about medicolegal liability

**Fairness, Ethics, and Bias:**
- Concerns about algorithmic bias and health equity
- Potential for AI to perpetuate disparities
- Ethical concerns about AI replacing human judgment
- Privacy and data security concerns

**Data Quality and Infrastructure:**

**Data-Related Barriers:**
- Missing data, noisy data, or data without proper labels
- Data quality issues lower system performance
- Lack of data standardization
- Insufficient data for training
- Data governance uncertainties

**Generalizability and Interoperability:**
- Most cited barriers deal with intervention generalizability
- AI trained on one population may not generalize
- Integration complexities with EHR workflows
- Lack of standardized interfaces

**Clinical Acceptance:**
- Concerns about performance expectations
- Uncertainty about when to trust vs. override AI
- Fear of degradation in performance over time
- Need for ongoing validation

**Workflow Impact:**
- Concerns about AI adding to workload
- Disruption to established workflows
- Time required to learn and interact
- Changes to clinical roles

**Governance and Regulation:**
- Unclear regulatory pathways
- Lack of established governance structures
- Uncertainty about accountability
- Absence of standards for validation
- Evolving regulatory landscape

### 2.4 Electronic Health Record Implementation Barriers

**Critical Success Factors Review:**

**2020 Rapid Umbrella Review:**
Fifteen inter-linked organizational, human and technological factors emerged as important for successful EHR implementations. Six themes for best practice: effective communication; successful system migration; sufficient hardware, technical equipment, support and training; safeguards for patient privacy; improved efficiency; and a sustainable business plan. **PMID: 33017724**

**2015 Critical Success Factors:**
The most significant success factor is commitment and involvement of all stakeholders. The lack of support and negative reaction to change is the most critical failure factor. **PMID: 26005276**

**2014 SWOT Analysis:**
Lack of hardware and infrastructures was the most important weakness. **PMID: 29228530**

**Leadership and Stakeholder Involvement:**
- Strong leadership
- Full involvement of clinical staff in design
- Mandatory staff training
- Strict adherence to timeline and budget

---

## 3. Facilitators and Success Factors

### 3.1 General Implementation Facilitators

**Leadership and Champions:**

**2024 Systematic Mixed Studies Review:**
With a clear mandate, dedicated time, and proper training, health personnel in champion roles can significantly contribute professional, technological, and personal competencies to facilitate technology adoption. **PMID: 38605304**

**2024 Scoping Review (Cancer Care):**
Facilitators included consideration of an individual's characteristics when identifying champions, time spent planning for specific responsibilities, working within supportive environment, and identifying champions embedded in target setting. **PMID: 39439009**

**2023 Mechanism Mapping:**
Theory-based healthcare facilitation components include staff engagement, role clarification, coalition-building through peer experiences and identifying champions, capacity-building. **PMID: 37194084**

**2020 Champion Attributes:**
Six key attributes emerged: influence, ownership, physical presence at point of change, persuasiveness, grit, and participative leadership style. **PMID: 32762726**

**2022 Systematic Review:**
A small body of literature reports association between use of champions and increased instrumental use of innovations, though more research needed on causal relationships. **PMID: 35869516**

**Stakeholder Engagement:**
- **Early Involvement:** Stakeholders involved from planning phase
- **Inter-disciplinary Teams:** Including clinicians, IT staff, administrators, patients
- **Co-design Approaches:** Users actively participate in design
- **Continuous Engagement:** Ongoing involvement throughout
- **Addressing Concerns:** Systematic identification and response

**Organizational Readiness:**
- **Resource Allocation:** Adequate time, money, personnel
- **Priority Alignment:** Aligned with strategy
- **Culture of Innovation:** Organizational openness
- **Past Success:** Positive prior experiences
- **Shared Commitment:** Collective resolve

**Training and Support:**
- **Comprehensive Programs:** Technical skills plus clinical rationale
- **Multiple Modalities:** Hands-on, didactic, peer learning
- **Ongoing Support:** Beyond initial training
- **Competency-Based:** Ensuring proficiency
- **Just-in-Time Support:** Help when needed

**Workflow Integration:**
- **Seamless Integration:** Embedded not add-on
- **Minimal Disruption:** Fit current practices
- **Time and Place Appropriate:** At point of care
- **Reduced Burden:** Decrease workload
- **Automation:** Automate where appropriate

### 3.2 CDSS Success Factors

**Landmark 2005 Systematic Review:**
A landmark systematic review (Kawamoto et al.) found CDSS significantly improved clinical practice in 68% of trials. Success associated with:
1. Automatic provision of decision support
2. Decision support at time and location of care
3. Actionable recommendations
**PMID: 15790683**

**Critical Success Features:**

**2020 Overview:**
An overview identified benefits, risks, and strategies for success in CDSS. Success requires integration into clinician workflow, provision of evidence-based recommendations at point of care, and minimization of alert fatigue. **PMID: 31998276**

**Alert Management Strategies:**

**2023 Semi-Automated System:**
A semi-automated CDSS with clinical pharmacist review achieved 89.8% acceptance for direct physician notifications and 68.4% for pharmacist-reviewed notifications, demonstrating value of human-AI collaboration. **PMID: 37454289**

**2020 Machine Learning Approach:**
Machine learning prediction models developed to predict physicians' responses to reduce alert fatigue from disease medication-related CDSSs. **PMID: 33211018**

**2023 Refining Clinical Phenotypes:**
Refining clinical phenotypes can improve clinical decision support and reduce alert fatigue. **PMID: 37437601**

**2024 Machine Learning CDSS:**
Machine learning based CDSS (MedGuard) has ability to improve patients' safety by triggering clinically valid alerts. Studies show ML can reduce alert fatigue while maintaining safety. **PMID: 37924770**

**2023 Passive vs. Interruptive:**
Replacing burdensome interruptive alerts with passive clinical decision support can address alert fatigue. **PMID: 38086417**

**Alert Management Principles:**
- Reserve interruptive alerts for high-severity issues
- Use passive displays for lower-priority information
- Allow customization based on role and setting
- Monitor override rates by alert type
- Disable or modify frequently overridden alerts
- Regularly update alert logic

### 3.3 AI-Specific Facilitators

**Performance Expectancy and Facilitating Conditions:**

Scoping reviews identify these as most frequent and consistent drivers:

**Performance Expectancy:**
- Clear demonstration of AI improving outcomes
- Evidence of time savings or efficiency gains
- Demonstrated accuracy superior to current methods
- Perceived usefulness for clinical decision-making
- Tangible benefits to clinicians and patients

**Facilitating Conditions:**
- Availability of comprehensive training
- Access to technical assistance
- Adequate IT infrastructure
- Integration with existing EHR systems
- Dedicated implementation support teams

**Stakeholder Involvement:**
- Involvement as early as possible from planning stage
- Inter-disciplinary groups: clinicians, users, leaders, IT
- Co-creation and user-centered design
- Continuous feedback loops
- Addressing concerns about autonomy

**Governance and Oversight:**
- Robust governance structures
- Clear policies for validation and monitoring
- Ethical review processes
- Mechanisms for detecting and addressing bias
- Defined accountability frameworks

**Transparency and Explainability:**
- Providing explanations for recommendations
- Visualizing confidence levels and uncertainty
- Showing evidence basis
- Making reasoning interpretable
- Supporting clinician override

**Continuous Monitoring:**
- Real-time performance monitoring
- Detecting model drift and degradation
- Rapid response to issues
- Regular validation against ground truth
- Feedback mechanisms from users

---

## 4. Implementation Strategies That Work

### 4.1 ERIC: Expert Recommendations for Implementing Change

The ERIC project systematically compiled and refined implementation strategy terminology through a modified Delphi process.

**Primary Publications:**
- Powell BJ, Waltz TJ, Chinman MJ, et al. A refined compilation of implementation strategies: results from the Expert Recommendations for Implementing Change (ERIC) project. Implement Sci. 2015;10:21. **PMID: 25889199**
- Waltz TJ, Powell BJ, Chinman MJ, et al. Expert Recommendations for Implementing Change (ERIC): protocol for a mixed methods study. Implement Sci. 2014;9:39. **PMID: 24669765**

**Overview:**
- **73 discrete implementation strategies** organized into **9 content areas**
- Developed to address inconsistent language
- Each strategy has clear definition
- Provides common vocabulary

**Recent ERIC Research:**

**2023 Sustainment Analysis:**
Surface level changes were made to definitions of 41 of the 73 ERIC strategies to explicitly address sustainment. **PMID: 36925827**

**2023 Cognitive Interviews:**
The ERIC compilation includes 73 defined implementation strategies clustered into nine content areas. This taxonomy has been used to track implementation strategies over time using surveys. **PMID: 37085937**

**2023 LMIC Application:**
Most studies (53.3%) explicitly matched implementation strategies to ERIC compilation, with 64 (87.3%) of the 73 ERIC strategies being represented in low- and middle-income countries. **PMID: 37904218**

**2024 Systematic Review:**
A systematic review of experimentally tested implementation strategies from 2010-2022 found the most frequently tested strategies were Distribute Educational Materials (n=99), Conduct Educational Meetings (n=96), Audit and Provide Feedback (n=76), and External Facilitation (n=59). **PMID: 38915102**

**The Nine Strategy Clusters:**

1. **Use Evaluative and Iterative Strategies**
2. **Provide Interactive Assistance**
3. **Adapt and Tailor to Context**
4. **Develop Stakeholder Interrelationships**
5. **Train and Educate Stakeholders**
6. **Support Clinicians**
7. **Engage Consumers**
8. **Utilize Financial Strategies**
9. **Change Infrastructure**

**Application Guidance:**
- Match strategies to identified barriers
- Multifaceted approaches outperform single strategies
- Context-specific tailoring essential
- Combinations should be logically coherent

### 4.2 Implementation Planning Frameworks

**EPIS (Exploration, Preparation, Implementation, Sustainment):**

A process model describing four well-defined phases:

**Systematic Review:**
A 2019 systematic review examined EPIS framework applications. **PMID: 30611251**

**Phases:**
1. **Exploration:** Needs and fit assessment, decision to adopt
2. **Preparation:** Barrier/facilitator identification, planning, resource allocation
3. **Implementation:** Active execution, training, fidelity monitoring, early problem-solving
4. **Sustainment:** Long-term continuation, integration into routine operations

**Implementation Mapping:**

A systematic five-task process based on Intervention Mapping methodology:

**Primary Publication:**
- Fernandez ME, ten Hoor GA, van Lieshout S, et al. Implementation Mapping: Using Intervention Mapping to Develop Implementation Strategies. Front Public Health. 2019;7:158. **PMID: 31275916**

**Five Tasks:**
1. Implementation Needs Assessment
2. Define Outcomes and Objectives
3. Select Methods and Strategies
4. Produce Implementation Materials
5. Evaluate Implementation

### 4.3 Context Assessment Strategies

**Defining and Assessing Context:**

**2020 Systematic Review:**
Context remains poorly understood in implementation science, with lack of consensus regarding how it should be defined and captured. Studies work to provide insight into how context is defined and assessed within healthcare implementation science literature. **PMID: 32600396**

**2020 Coding Framework:**
Development of an integrative coding framework for evaluating context within implementation science, guided by CFIR sub-elements. **PMID: 32539710**

**2019 Scoping Review:**
Context matters in implementation science. A scoping review of determinant frameworks found variation in how frameworks were developed and considerable inconsistency in terms, conceptualization, and determinants accounted for. **PMID: 30909897**

**COACH Tool:**
Health system context and implementation of evidence-based practicesdevelopment and validation of the Context Assessment for Community Health (COACH) tool for low- and middle-income settings. **PMID: 26276443**

**2023 Scoping Review:**
A scoping review of outer context constructs in dissemination and implementation science theories, models, and frameworks. **PMID: 36694938**

**2022 Evidence Gap Map:**
Methodological approaches to study context in intervention implementation studies show inconsistencies currently limit progress. **PMID: 36517765**

### 4.4 Fidelity-Adaptation Balance

One of implementation science's central debates concerns balancing fidelity to evidence-based interventions and adaptation to local contexts.

**Key Publications:**

**2020 MADI Framework:**
The Model for Adaptation Design and Impact (MADI) provides a comprehensive model for understanding adaptations' impact. **PMID: 32552857**

**2016 Modified Framework:**
A modified theoretical framework to assess implementation fidelity of adaptive public health interventions. **PMID: 27391959**

**2020 IDEA Framework:**
Iterative Decision-making for Evaluation of Adaptations (IDEA): A decision tree for balancing adaptation, fidelity, and intervention impact. **PMID: 31970812**

**Recent Applications:**

**2025 Virtual Adaptation:**
Implementation fidelity of a virtual adaptation examined, with interventionists and observers reporting high levels of dosage, adherence, quality of delivery, and participant engagement. **PMID: 40444872**

**2024 Audit and Feedback:**
Assessment of adaptation and fidelity in audit and feedback-based intervention to improve transition to adult type 1 diabetes care adopted a balanced approach. **PMID: 38500183**

**2023 Implementation Playbook:**
Getting to implementation: Adaptation of an implementation playbook. **PMID: 36684876**

**The Balanced View (Emerging Consensus):**

**Core-Adaptive Distinction:**
- **Core Components:** Essential elements requiring fidelity
- **Adaptive Periphery:** Elements that can be modified

**FRAME:**
Framework for Reporting Adaptations and Modifications-Enhanced systematically documents adaptations, tracks when, what, why, and how modifications occurred.

**Relevance to AI Implementation:**

For AI interventions:
- **Core Components (High Fidelity):**
  - Algorithm integrity
  - Input data quality requirements
  - Validated use cases
  - Safety thresholds

- **Adaptive Elements:**
  - User interface customization
  - Workflow integration approaches
  - Training modalities
  - Implementation strategies
  - Local governance processes

---

## 5. Sustainability of Healthcare Interventions

### 5.1 The Sustainability Challenge

**Magnitude:**
- Estimated 30-40% of implemented interventions sustained
- Many evidence-based interventions fail to achieve institutionalization
- Sustainability often receives inadequate attention
- Funding frequently ends before embedding

**Why It Matters:**
Implementation requires significant investment. Discontinued interventions waste resources, represent missed opportunities, reduce patient access, cause change fatigue, and erode organizational trust.

### 5.2 Sustainability Frameworks and Models

**Key Publications:**

**2018 Navigating the Sustainability Landscape:**
A comprehensive systematic review identified extensive variation: 62 publications including 32 frameworks, 16 models, 8 tools, 4 strategies, 1 checklist, and 1 process. Identified 40 individual constructs for sustainability. **PMID: 29426341**

**2018 Annual Review:**
The sustainability of evidence-based interventions and practices in public health and health care. Priorities include conceptual consistency, operational clarity, developing evidence about value of sustaining interventions, and identifying correlates of sustainability. **PMID: 29328872**

**2015 Sustainability Research Agenda:**
Sustainability of evidence-based healthcare: research agenda, methodological advances, and infrastructure support. **PMID: 26062907**

**2021 Triple C Model:**
Implementation of sustainable complex interventions in health care services: the triple C model supports sustainability through Context, Capacity, and Continuation. **PMID: 33588823**

**2023 Knowledge Translation Sustainability:**
Knowledge translation strategies to support sustainability of evidence-based interventions in healthcare: a scoping review. **PMID: 38049900**

**2022 Integrative Review:**
Identifying existing approaches used to evaluate sustainability of evidence-based interventions in healthcare: an integrative review. **PMID: 36243760**

**2020 Built to Last:**
Built to last? The sustainability of healthcare system improvements, programmes and interventions: a systematic integrative review found the body of literature limited by inconsistent definitions and measures. **PMID: 32487579**

**2016 Scoping Review:**
Sustainability of knowledge translation interventions in healthcare decision-making: a scoping review included 62 studies (103 publications, 260,688 patients) examining chronic disease management. **PMID: 27097827**

### 5.3 Sustainability Determinants

**Common Sustainability Determinants:**

**Intervention Characteristics:**
- Demonstrated effectiveness
- Compatibility with mission
- Adaptability to circumstances
- Feasibility with resources
- Lower complexity

**Organizational Factors:**
- Leadership commitment beyond initial implementation
- Integration into routine workflows
- Adequate ongoing resources
- Supportive culture
- Capacity for continuous improvement

**Individual Factors:**
- Staff turnover and succession planning
- Sustained skills and knowledge
- Continued motivation
- Role clarity and accountability

**External Environment:**
- Continued funding and reimbursement
- Policy support
- Community engagement
- Political and economic stability

**Implementation Process:**
- Early sustainability planning
- Stakeholder ownership
- Monitoring and feedback systems
- Continuous quality improvement
- Documentation and knowledge management

### 5.4 Sustainability Strategies

**Evidence-Based Strategies:**

**Financial Sustainability:**
- Secure ongoing funding sources
- Integrate into regular budgets
- Demonstrate cost-effectiveness
- Align with payment models
- Diversify funding streams

**Integration and Routinization:**
- Embed in standard operating procedures
- Integrate into training for new staff
- Include in job descriptions
- Align with organizational goals
- Become "how we do things here"

**Monitoring and Evaluation:**
- Establish ongoing data collection
- Regular outcome monitoring
- Feedback to stakeholders
- Continuous quality improvement
- Adapt based on performance

---

## 6. Scale-Up and Spread of Innovations

### 6.1 Scale-Up Framework and Evidence

**Key Publications:**

**2019 Spreading and Scaling Up:**
Review references systematic reviews on diffusion of innovations and frameworks for scaling health interventions. **PMID: 31076440**

**2022 Digital Innovations Scale-Up:**
Scale-up of digital innovations in health care is vital for population-wide impact. Expert commentary identified enablers and barriers. **PMID: 35275065**

**2016 Framework from Africa:**
A framework for scaling up health interventions from large-scale improvement initiatives in Africa describes three core components: activities to reach full scale, mechanisms for adoption, and underlying support systems. **PMID: 26821910**

**2020 eConsult Scale-Up:**
Key factors for national spread and scale-up of an eConsult innovation examined spreading from local to national level in Canada. **PMID: 32493357**

**2019 Unpredictable Journeys:**
The unpredictable journeys of spreading, sustaining and scaling healthcare innovations: a scoping review focuses on spread, sustainability and scale-up (3S) of innovation. **PMID: 31519185**

**2012 Stakeholder-Driven Agenda:**
A stakeholder-driven agenda for advancing the science and practice of scale-up and spread addresses research gap at regional, national, or international levels. **PMID: 23216748**

### 6.2 Scale-Up Strategies

**Vertical vs. Horizontal:**

**Vertical (Scaling Up):**
- Institutionalizing in policy and budgets
- Changing laws, regulations, standards
- Securing sustainable funding
- Creating enabling environment

**Horizontal (Scaling Out):**
- Expanding to more sites/settings
- Reaching more beneficiaries
- Geographic expansion
- Replication in new contexts

**Both Typically Needed:**
Horizontal expansion without vertical support often unsustainable. Vertical policy without horizontal implementation has no impact. Successful scale-up combines both.

### 6.3 Spread Mechanisms

**Greenhalgh's Diffusion Framework:**

Extends Rogers' theory for healthcare organizations with key mechanisms:

1. **Peer-to-Peer Diffusion**
2. **Formal Dissemination**
3. **Imitation**
4. **Implementation Support**

**Social Network Approaches:**
- Identify and engage network hubs
- Target opinion leaders
- Create new connections
- Use network mapping

---

## 7. Important Studies, Evidence, and PubMed Citations

### 7.1 Landmark Framework Publications

**RE-AIM:**
- Glasgow RE, Vogt TM, Boles SM. Evaluating the public health impact of health promotion interventions: the RE-AIM framework. Am J Public Health. 1999;89(9):1322-1327. **PMID: 10474547**
- Glasgow RE, Holtrop JS, Rabin BA. RE-AIM Planning and Evaluation Framework: Adapting to New Science and Practice With a 20-Year Review. Front Public Health. 2019;7:64. **PMID: 30984733**
- Holtrop JS, et al. RE-AIM in the Real World: Use of the RE-AIM Framework for Program Planning and Evaluation in Clinical and Community Settings. Front Public Health. 2019;10:755. **PMID: 31824911**
- Aligning the planning, development, and implementation of complex interventions to local contexts with an equity focus: application of the PRISM/RE-AIM Framework. 2024. **PMID: 38408990**

**CFIR:**
- Damschroder LJ, et al. Fostering implementation of health services research findings into practice: a consolidated framework for advancing implementation science. Implement Sci. 2009;4:50. **PMID: 19664226**
- Damschroder LJ, et al. The updated Consolidated Framework for Implementation Research based on user feedback. Implement Sci. 2022;17(1):75. **PMID: 36309746**
- Kirk MA, et al. The Consolidated Framework for Implementation Research (CFIR) User Guide: a five-step guide for conducting implementation research using the framework. Implement Sci. 2025;20:5. **PMID: 40819067**
- Conceptualizing outcomes for use with the Consolidated Framework for Implementation Research (CFIR): the CFIR Outcomes Addendum. 2022. **PMID: 35065675**
- A systematic review of the use of the Consolidated Framework for Implementation Research. 2016. **PMID: 27189233**
- Evaluating and optimizing the consolidated framework for implementation research (CFIR) for use in low- and middle-income countries: a systematic review. 2020. **PMID: 32164692**

**Diffusion of Innovations:**
- Greenhalgh T, Robert G, Macfarlane F, Bate P, Kyriakidou O. Diffusion of innovations in service organizations: systematic review and recommendations. Milbank Q. 2004;82(4):581-629. **PMID: 15595944**
- Dearing JW, Cox JG. Diffusion Of Innovations Theory, Principles, And Practice. Health Aff. 2018;37(2):183-190. **PMID: 29401011**
- Diffusion of innovations: a guiding framework for public health. 2021. **PMID: 34058897**
- Innovation Diffusion Across 13 Specialties and Associated Clinician Characteristics. 2024. **PMID: 38262012**
- Disseminating innovations in health care. 2003. **PMID: 12697800**

**NASSS:**
- Greenhalgh T, Wherton J, Papoutsi C, et al. Beyond Adoption: A New Framework for Theorizing and Evaluating Nonadoption, Abandonment, and Challenges to the Scale-Up, Spread, and Sustainability of Health and Care Technologies. J Med Internet Res. 2017;19(11):e367. **PMID: 29092808**
- The NASSS Framework - A Synthesis of Multiple Theories of Technology Implementation. 2019. **PMID: 31411163**
- The NASSS-CAT Tools for Understanding, Guiding, Monitoring, and Researching Technology Implementation Projects in Health and Social Care: Protocol for an Evaluation Study in Real-World Settings. 2020. **PMID: 32401224**
- The NASSS (Non-Adoption, Abandonment, Scale-Up, Spread and Sustainability) framework use over time: A scoping review. 2025. **PMID: 40096260**

**Normalization Process Theory:**
- May CR, Finch T, Ballini L, et al. Evaluating complex interventions and health technologies using normalization process theory: development of a simplified approach and web-enabled toolkit. BMC Health Serv Res. 2011;11:245. **PMID: 21961827**
- May CR, Mair F, Finch T, et al. Development of a theory of implementation and integration: Normalization Process Theory. Implement Sci. 2009;4:29. **PMID: 19460163**
- May CR, Cummings A, Girling M, et al. Using Normalization Process Theory in feasibility studies and process evaluations of complex healthcare interventions: a systematic review. Implement Sci. 2018;13(1):80. **PMID: 29879986**
- Improving the normalization of complex interventions: part 2 - validation of the NoMAD instrument. 2018. **PMID: 30442094**
- A qualitative systematic review of studies using the normalization process theory to research implementation processes. 2014. **PMID: 24383661**

**Organizational Readiness:**
- Weiner BJ. A theory of organizational readiness for change. Implement Sci. 2009;4:67. **PMID: 19840381**
- Weiner BJ, Amick H, Lee SY. Conceptualization and measurement of organizational readiness for change: a review of the literature. Med Care Res Rev. 2008;65(4):379-436. **PMID: 18511812**
- Shea CM, Jacobs SR, Esserman DA, Bruce K, Weiner BJ. Organizational readiness for implementing change: a psychometric assessment of a new measure. Implement Sci. 2014;9:7. **PMID: 24410955**
- Organizational readiness for implementing change in acute care hospitals: An analysis of a cross-sectional, multicentre study. 2018. **PMID: 30019540**
- Clinicians' perceptions of organizational readiness for change in the context of clinical information system projects: insights from two cross-sectional surveys. 2011. **PMID: 21356080**

**Implementation Outcomes:**
- Proctor E, Silmere H, Raghavan R, et al. Outcomes for implementation research: conceptual distinctions, measurement challenges, and research agenda. Adm Policy Ment Health. 2011;38(2):65-76. **PMID: 20957426**
- Lewis CC, et al. Ten years of implementation outcomes research: a scoping review. Implement Sci. 2023;18:31. **PMID: 37491242**

### 7.2 Implementation Strategies (ERIC)

- Powell BJ, Waltz TJ, Chinman MJ, et al. A refined compilation of implementation strategies: results from the Expert Recommendations for Implementing Change (ERIC) project. Implement Sci. 2015;10:21. **PMID: 25889199**
- Waltz TJ, Powell BJ, Chinman MJ, et al. Expert Recommendations for Implementing Change (ERIC): protocol for a mixed methods study. Implement Sci. 2014;9:39. **PMID: 24669765**
- Perry CK, et al. Do the Expert Recommendations for Implementing Change (ERIC) strategies adequately address sustainment? Front Health Serv. 2023;2:905909. **PMID: 36925827**
- Refining Expert Recommendations for Implementing Change (ERIC) strategy surveys using cognitive interviews with frontline providers. 2023. **PMID: 37085937**
- Application of the Expert Recommendations for Implementing Change (ERIC) compilation of strategies to health intervention implementation in low- and middle-income countries: a systematic review. 2023. **PMID: 37904218**
- A systematic review of experimentally tested implementation strategies across health and human service settings: evidence from 2010-2022. 2024. **PMID: 38915102**
- Enhancing the Impact of Implementation Strategies in Healthcare: A Research Agenda. 2019. **PMID: 30723713**
- The effectiveness of implementation strategies for promoting evidence informed interventions in allied healthcare: a systematic review. 2021. **PMID: 33736631**

### 7.3 Barriers to Evidence-Based Practice and Clinical Practice Change

- Individual, health system, and contextual barriers and facilitators for the implementation of clinical practice guidelines: a systematic metareview. 2020. **PMID: 32600417**
- The barriers and facilitators for the implementation of clinical practice guidelines in healthcare: an umbrella review of qualitative and quantitative literature. 2023. **PMID: 37657616**
- Barriers and enablers to implementing clinical practice guidelines in primary care: an overview of systematic reviews. 2023. **PMID: 36609329**
- Barriers and facilitators of nurses' use of clinical practice guidelines: An integrative review. 2016. **PMID: 27297368**
- Barriers to and facilitators of clinical practice guideline use in nursing homes. 2007. **PMID: 17767682**

### 7.4 CDSS and Alert Fatigue

- Kawamoto K, Houlihan CA, Balas EA, Lobach DF. Improving clinical practice using clinical decision support systems: a systematic review of trials to identify features critical to success. BMJ. 2005;330(7494):765. **PMID: 15790683**
- Identifying barriers and facilitators to successful implementation of computerized clinical decision support systems in hospitals: a NASSS framework-informed scoping review. 2023. **PMID: 37495997**
- Barriers and facilitators to the adoption of electronic clinical decision support systems: a qualitative interview study with UK general practitioners. 2021. **PMID: 34154580**
- Barriers and Facilitators to the Use of Clinical Decision Support Systems in Primary Care: A Mixed-Methods Systematic Review. 2023. **PMID: 36690490**
- What hinders the uptake of computerized decision support systems in hospitals? A qualitative study and framework for implementation. 2017. **PMID: 28915822**
- Reasons For Physicians Not Adopting Clinical Decision Support Systems: Critical Analysis. 2018. **PMID: 29669706**
- Factors That Impact the Adoption of Clinical Decision Support Systems (CDSS) for Antibiotic Management. 2021. **PMID: 33669353**

**Alert Fatigue:**
- Improving Utilization of Clinical Decision Support Systems by Reducing Alert Fatigue: Strategies and Recommendations. 2016. **PMID: 27350464**
- Machine Learning Approach to Reduce Alert Fatigue Using a Disease Medication-Related Clinical Decision Support System: Model Development and Validation. 2020. **PMID: 33211018**
- Tackling alert fatigue with a semi-automated clinical decision support system: quantitative evaluation and end-user survey. 2023. **PMID: 37454289**
- Effects of workload, work complexity, and repeated alerts on alert fatigue in a clinical decision support system. 2017. **PMID: 28395667**
- Ability of machine-learning based clinical decision support system to reduce alert fatigue, wrong-drug errors, and alert users about look alike, sound alike medication. 2023. **PMID: 37924770**
- Addressing Alert Fatigue by Replacing a Burdensome Interruptive Alert with Passive Clinical Decision Support. 2024. **PMID: 38086417**
- Distinct components of alert fatigue in physicians' responses to a noninterruptive clinical decision support alert. 2022. **PMID: 36264258**
- Refining Clinical Phenotypes to Improve Clinical Decision Support and Reduce Alert Fatigue: A Feasibility Study. 2023. **PMID: 37437601**

### 7.5 AI Implementation in Healthcare

**AI Implementation Frameworks:**
- FUTURE-AI: international consensus guideline for trustworthy and deployable artificial intelligence in healthcare. 2025. **PMID: 39909534**
- Implementation framework for AI deployment at scale in healthcare systems. 2025. **PMID: 40384926**
- The Clinical Practice Integration of Artificial Intelligence (CPI-AI) framework. 2024. **PMID: 39288942**
- Deployment of machine learning algorithms to predict sepsis: systematic review and application of the SALIENT clinical AI implementation framework. 2023. **PMID: 37172264**
- Evaluation framework to guide implementation of AI systems into healthcare settings. 2021. **PMID: 34642177**
- A framework for the oversight and local deployment of safe and high-quality prediction models. 2022. **PMID: 35641123**
- Clinical trials informed framework for real world clinical implementation and deployment of artificial intelligence applications. 2025. **PMID: 39962232**

**AI Applications and Challenges:**
- Machine learning and artificial intelligence in research and healthcare. 2022. **PMID: 35135685**
- Machine Learning in Healthcare. 2021. **PMID: 35273459**
- Machine learning applications in healthcare clinical practice and research. 2025. **PMID: 39764535**
- Machine learning and artificial intelligence: applications in healthcare epidemiology. 2022. **PMID: 36168500**
- Advancing Patient Care: How Artificial Intelligence Is Transforming Healthcare. 2023. **PMID: 37623465**

**AI Barriers and Facilitators:**
- Barriers to and Facilitators of Artificial Intelligence Adoption in Health Care: Scoping Review. 2024. (Mahomed S)
- Artificial Intelligence Implementation in Healthcare: A Theory-Based Scoping Review of Barriers and Facilitators. 2022. **PMID: 36498752** (Gaube et al.)
- Barriers to and facilitators of clinician acceptance and use of artificial intelligence in healthcare settings: a scoping review. 2025. (Kien C et al.)

**Clinical Prediction Models:**
- Implementation and Updating of Clinical Prediction Models: A Systematic Review. 2025. **PMID: 40599890**
- Implementation approaches and barriers for rule-based and machine learning-based sepsis risk prediction tools: a qualitative study. 2022. **PMID: 35474719**
- Overcoming barriers to the adoption and implementation of predictive modeling and machine learning in clinical care: what can we learn from US academic medical centers? 2020. **PMID: 32734155**
- Understanding clinical prediction models as 'innovations': a mixed methods study in UK family practice. 2016. **PMID: 27506547**
- Implementation of Prediction Models in the Emergency Department from an Implementation Science Perspective. 2023. **PMID: 36925394**

### 7.6 Sustainability

- Lennox L, Maher L, Reed J. Navigating the sustainability landscape: a systematic review of sustainability approaches in healthcare. Implement Sci. 2018;13:27. **PMID: 29426341**
- Shelton RC, Cooper BR, Stirman SW. The sustainability of evidence-based interventions and practices in public health and health care. Annu Rev Public Health. 2018;39:55-76. **PMID: 29328872**
- Sustainability of evidence-based healthcare: research agenda, methodological advances, and infrastructure support. 2015. **PMID: 26062907**
- Implementation of sustainable complex interventions in health care services: the triple C model. 2021. **PMID: 33588823**
- Identifying existing approaches used to evaluate the sustainability of evidence-based interventions in healthcare: an integrative review. 2022. **PMID: 36243760**
- Built to last? The sustainability of healthcare system improvements, programmes and interventions: a systematic integrative review. 2020. **PMID: 32487579**
- Knowledge translation strategies to support the sustainability of evidence-based interventions in healthcare: a scoping review. 2023. **PMID: 38049900**
- Sustainability of knowledge translation interventions in healthcare decision-making: a scoping review. 2016. **PMID: 27097827**

### 7.7 Fidelity and Adaptation

- Stirman SW, et al. Towards a comprehensive model for understanding adaptations' impact: the model for adaptation design and impact (MADI). Implement Sci. 2015;10:56. **PMID: 32552857** (2020 publication)
- Prez D, et al. A modified theoretical framework to assess implementation fidelity of adaptive public health interventions. Implement Sci. 2016;11:91. **PMID: 27391959**
- Iterative Decision-making for Evaluation of Adaptations (IDEA): A decision tree for balancing adaptation, fidelity, and intervention impact. 2020. **PMID: 31970812**
- Implementation Fidelity of a Virtual Adaptation of the Guiding Good Choices Program. 2025. **PMID: 40444872**
- An assessment of adaptation and fidelity in the implementation of an audit and feedback-based intervention. 2024. **PMID: 38500183**
- Getting to implementation: Adaptation of an implementation playbook. 2023. **PMID: 36684876**

### 7.8 Scale-Up and Spread

- Spreading and scaling up innovation and improvement. 2019. **PMID: 31076440**
- Scale-up of Digital Innovations in Health Care: Expert Commentary on Enablers and Barriers. 2022. **PMID: 35275065**
- Barker PM, Reid A, Schall MW. A framework for scaling up health interventions: lessons from large-scale improvement initiatives in Africa. Implement Sci. 2016;11:12. **PMID: 26821910**
- Key factors for national spread and scale-up of an eConsult innovation. 2020. **PMID: 32493357**
- The unpredictable journeys of spreading, sustaining and scaling healthcare innovations: a scoping review. 2019. **PMID: 31519185**
- Milat AJ, et al. A stakeholder-driven agenda for advancing the science and practice of scale-up and spread in health. Implement Sci. 2012;7:118. **PMID: 23216748**

### 7.9 Champions and Facilitation

- The role of champions in the implementation of technology in healthcare services: a systematic mixed studies review. 2024. **PMID: 38605304**
- Champions to enhance implementation of clinical and community-based interventions in cancer: a scoping review. 2024. **PMID: 39439009**
- How does facilitation in healthcare work? Using mechanism mapping to illuminate the black box. 2023. **PMID: 37194084**
- Champions in context: which attributes matter for change efforts in healthcare? 2020. **PMID: 32762726**
- Facilitation roles and characteristics associated with research use by healthcare professionals: a scoping review. 2017. **PMID: 28801388**
- The effectiveness of champions in implementing innovations in health care: a systematic review. 2022. **PMID: 35869516**

### 7.10 Change Management Models

- Where Do Models for Change Management, Improvement and Implementation Meet? A Systematic Review of the Applications of Change Management Models in Healthcare. 2021. **PMID: 33737854**
- Change Management in Health Care. 2020. **PMID: 32345939**
- Creating change: Kotter's Change Management Model in action. 2023. **PMID: 37465754**
- Using Kotter's Change Framework to Implement and Sustain Multiple Complementary ICU Initiatives. 2017. **PMID: 28658182**
- Kotter's 8-step change model to improve hand hygiene compliance in intensive care unit: A 41-month prospective longitudinal quality improvement study. 2024. **PMID: 39561482**

### 7.11 EHR Implementation

- Successfully implementing a national electronic health record: a rapid umbrella review. 2020. **PMID: 33017724**
- Electronic health records: critical success factors in implementation. 2015. **PMID: 26005276**
- Electronic Health Record Implementation: A Review of Resources and Tools. 2019. **PMID: 31700751**
- Electronic Health Record Implementation: A SWOT Analysis. 2018. **PMID: 29228530**

### 7.12 Context Assessment

- Defining and assessing context in healthcare implementation studies: a systematic review. 2020. **PMID: 32600396**
- Development of an integrative coding framework for evaluating context within implementation science. 2020. **PMID: 32539710**
- Context matters in implementation science: a scoping review of determinant frameworks. 2019. **PMID: 30909897**
- Health system context and implementation of evidence-based practices-development and validation of the Context Assessment for Community Health (COACH) tool. 2015. **PMID: 26276443**
- A scoping review of outer context constructs in dissemination and implementation science theories, models, and frameworks. 2023. **PMID: 36694938**
- Methodological approaches to study context in intervention implementation studies: an evidence gap map. 2022. **PMID: 36517765**

### 7.13 Equity and Implementation Science

- Addressing health disparities through implementation science-a need to integrate an equity lens from the outset. 2022. **PMID: 35101088**
- Harnessing Implementation Science to Increase the Impact of Health Equity Research. 2017. **PMID: 28806362**
- Implementation science should give higher priority to health equity. 2021. **PMID: 33740999**
- Implementation Research Methodologies for Achieving Scientific Equity and Health Equity. 2019. **PMID: 30906154**
- Leveraging Implementation Science for Cardiovascular Health Equity: A Scientific Statement From the American Heart Association. 2022. **PMID: 36214131**
- Reframing implementation science to address inequities in healthcare delivery. 2020. **PMID: 32164706**

### 7.14 Hybrid Effectiveness-Implementation Trials

- Similarities and Differences Between Pragmatic Trials and Hybrid Effectiveness-Implementation Trials. 2024. **PMID: 38627320**
- Effectiveness-implementation hybrid designs: combining elements of clinical effectiveness and implementation research to enhance public health impact. 2012. **PMID: 22310560**
- Pragmatic clinical trials as hybrid effectiveness-implementation studies to shrink the evidence-to-practice gap. 2024. **PMID: 39514879**

---

## 8. Implications for Deploying AI Interventions at Scale

### 8.1 Unique Challenges of AI Implementation

AI interventions present distinctive implementation challenges beyond traditional healthcare IT:

**The Explainability Imperative:**
- Traditional CDSS provides rule-based recommendations that clinicians can trace
- Machine learning models often function as "black boxes" with opaque decision logic
- Clinicians need to understand AI reasoning to appropriately trust and use recommendations
- Explainability is not just a technical feature but a critical implementation determinant
- Lack of transparency inhibits adoption and appropriate use

**Implications:**
- Prioritize explainable AI approaches where possible (FUTURE-AI framework emphasizes explainability as core principle)
- Develop clear explanations for AI recommendations using lay language
- Visualize confidence levels and uncertainty
- Show evidence basis and similar cases
- Provide override options with documentation
- Train clinicians in AI literacy and appropriate use

**Dynamic Nature of AI Systems:**
- Traditional interventions are relatively static once implemented
- AI models may drift over time as data distributions change
- Models require ongoing monitoring, validation, and updating
- Performance can degrade silently without detection systems
- Updates may change behavior in ways users don't anticipate

**Implications:**
- Establish robust continuous monitoring systems
- Create processes for detecting model drift
- Implement governance for model updates and versioning
- Communicate changes to users proactively
- Build feedback loops from users about AI performance
- Plan for model retraining and revalidation

**Bias and Health Equity Concerns:**
- AI trained on non-representative data may perform poorly for underrepresented groups
- Algorithmic bias can perpetuate or exacerbate health disparities
- Fairness is not just technical but also involves stakeholder values
- Equity concerns are major barriers to AI acceptance
- Harm to vulnerable populations could undermine entire implementation

**Implications:**
- Conduct thorough bias audits before and during deployment
- Assess performance across demographic subgroups
- Engage diverse stakeholders in AI development and validation
- Monitor for differential performance by race, ethnicity, gender, age, SES
- Implement fairness constraints and mitigation strategies
- Build equity into implementation planning from the start (PMID: 35101088)
- Be transparent about limitations and known biases

**Data Dependencies:**
- AI requires high-quality, complete, structured data
- Missing data, data quality issues, and lack of standardization undermine AI
- Data infrastructure limitations are major barriers (PMID: 37495997)
- Interoperability challenges across systems
- Privacy and security concerns amplified with AI

**Implications:**
- Assess data quality and completeness before implementation
- Invest in data infrastructure as prerequisite
- Address interoperability systematically
- Establish robust data governance
- Implement privacy-preserving approaches
- Plan for data quality monitoring and improvement

### 8.2 Framework Selection and Integration

**No Single Framework Suffices:**

For complex AI implementations, integrate multiple complementary frameworks:

**Planning Phase:**
- **CFIR** for comprehensive barrier/facilitator assessment (updated 2022 version, PMID: 36309746)
- **Organizational Readiness** (Weiner, PMID: 19840381) for assessing preparedness
- **MUSIQ** for understanding contextual factors
- **Diffusion of Innovations** for understanding adoption determinants
- **Implementation Mapping** (PMID: 31275916) for systematic planning

**Implementation Phase:**
- **EPIS** for guiding phase-by-phase progression
- **ERIC strategies** (73 strategies, PMID: 25889199) for selecting specific tactics
- **NPT** (PMID: 29879986) for understanding normalization and embedding
- **TDF** for addressing behavior change mechanisms
- **Proctor's framework** (PMID: 20957426) for measuring implementation outcomes
- **NASSS** (PMID: 29092808) for assessing complexity and predicting challenges

**Evaluation and Sustainability Phase:**
- **RE-AIM** (PMID: 30984733) for comprehensive evaluation
- **Sustainability frameworks** (PMID: 29426341) for long-term planning
- **Fidelity/adaptation frameworks** (MADI, PMID: 32552857) for managing evolution
- **ExpandNet** for scale-up planning

**AI-Specific Frameworks:**
- **FUTURE-AI** (PMID: 39909534): Fairness, Universality, Traceability, Usability, Robustness, Explainability
- **SALIENT** (PMID: 37172264): Staged implementation framework with 5 stages
- **CPI-AI** (PMID: 39288942): Clinical Practice Integration of AI - five-stage approach

**Practical Framework Integration:**
1. Map implementation questions to appropriate frameworks
2. Use frameworks complementarily, not redundantly
3. Adapt frameworks to specific AI intervention and context
4. Engage stakeholders in framework selection
5. Use pragmaticallyframeworks should help, not burden

### 8.3 Phased Implementation Strategy

**Avoid "Big Bang" Deployments:**

Stepwise, learning-oriented implementation reduces risk and improves outcomes:

**Phase 1: Proof of Concept (Laboratory)**
- Validate AI algorithm performance
- Assess technical feasibility
- Identify core vs. adaptable components
- Duration: Varies, often months to 1-2 years

**Phase 2: Pilot Implementation (Limited Real-World)**
- Single site or small number of sites
- Controlled conditions with intensive support
- Focus on workflow integration and usability
- Gather user feedback and refine
- Assess implementation barriers and facilitators using CFIR or NASSS
- Duration: 3-12 months typically

**Phase 3: Early Expansion (Multi-Site)**
- Expand to diverse sites to test generalizability
- Build implementation infrastructure
- Develop training and support systems
- Refine implementation strategies
- Monitor sustainability
- Duration: 1-2 years

**Phase 4: Broader Scale-Up**
- Wider deployment across health system
- Leverage learning from early phases
- Implement standardized approaches with local tailoring
- Build sustainability mechanisms
- Duration: 2-5 years

**Phase 5: Full Integration and Sustainability**
- Routine operations and ongoing improvement
- Continuous monitoring and adaptation
- Sustained resource allocation
- Knowledge management
- Duration: Ongoing

**Learning Between Phases:**
- Formal evaluation between phases
- Go/no-go decision points
- Refinement based on evidence
- Stakeholder feedback integration
- Adjustment of implementation strategies

### 8.4 Critical Success Factors for AI at Scale

**1. Executive Leadership Commitment:**
- AI implementation requires sustained leadership support
- Leaders must champion AI as strategic priority
- Resource allocation beyond pilot phase
- Accountability at executive level
- Visible endorsement builds legitimacy

**2. Clinical Champion Network:**
- Identify respected clinician champions (PMID: 38605304)
- Distribute champions across specialties and sites
- Empower champions with time, resources, authority (PMID: 39439009)
- Leverage champions for peer influence
- Succession planning for champion roles

**3. Robust Governance:**
- Establish AI governance committee with multidisciplinary membership
- Clear policies for AI validation, deployment, monitoring (PMID: 40384926)
- Ethical review processes
- Defined accountability for AI systems
- Mechanisms for addressing bias and fairness
- Processes for model updates and changes

**4. User-Centered Design:**
- Engage end-users from earliest design stages
- Iterative usability testing and refinement
- Design for actual workflows, not idealized ones
- Minimize burden and maximize benefit to users
- Customize interfaces for different user roles

**5. Seamless Workflow Integration:**
- Embed AI into existing EHR systems (major barrier when lacking, PMID: 37495997)
- Avoid separate logins or systems
- Deliver insights at point of care
- Minimize clicks and navigation
- Automate where appropriate
- Design for efficient clinical decision-making

**6. Comprehensive Training Ecosystem:**
- Training in both technical use and clinical rationale
- Multiple modalities: online, hands-on, peer learning
- Role-specific training
- Ongoing education for new users and updates
- Train-the-trainer approaches for scale
- Competency assessment

**7. Technical Infrastructure:**
- Adequate IT infrastructure for AI deployment
- Data quality and completeness (major barrier, PMID: 37495997)
- Interoperability with EHR systems
- Robust security and privacy protections
- Performance monitoring capabilities
- Scalable architecture

**8. Implementation Support:**
- Dedicated implementation teams
- Technical assistance readily available
- Troubleshooting and problem-solving
- Rapid response to issues
- Learning collaboratives across sites
- Communities of practice

**9. Continuous Monitoring:**
- Real-time performance monitoring (critical for AI, PMID: 40384926)
- User engagement and utilization tracking
- Clinical outcome assessment
- Detection of model drift
- Bias monitoring across subgroups
- User feedback collection and response

**10. Demonstrated Value:**
- Evidence of clinical benefit (performance expectancy, PMID: 36498752)
- Efficiency gains for users
- Return on investment
- Patient outcome improvements
- Share success stories widely
- Celebrate wins and learn from challenges

### 8.5 Managing Alert Fatigue for AI Systems

Given that alert fatigue undermines CDSS with 90-95% override rates (PMID: 28395667), proactive strategies are essential:

**Prevention Strategies:**

**1. Highly Selective Alerting:**
- Reserve interruptive alerts for high-severity, actionable issues
- Use tiered alerting: interruptive, passive, silent (PMID: 38086417)
- Ensure alerts are evidence-based and clinically significant
- Avoid alerts for issues already addressed
- Context-aware alerting

**2. Human-AI Collaboration:**
- Semi-automated systems with expert review (e.g., clinical pharmacist)
- AI flags issues; humans prioritize and communicate
- Studies show 72-90% acceptance with this model vs. 5-10% for direct automated alerts (PMID: 37454289)
- Combines AI scale with human judgment and communication

**3. Machine Learning to Reduce Alert Fatigue:**
- Use ML to predict which alerts clinicians are likely to accept (PMID: 33211018)
- ML-based CDSS can improve safety by triggering clinically valid alerts (PMID: 37924770)
- Refine clinical phenotypes to improve relevance (PMID: 37437601)

**4. Customization and Personalization:**
- Allow users to customize alert thresholds
- Role-based alerting
- Specialty-specific configurations
- Learning from individual user patterns
- Opt-in for optional alerts

**5. Clear, Actionable Information:**
- Specific recommendations, not vague warnings
- Pre-populated orders to facilitate desired action
- Clear explanation of why alert triggered
- Evidence basis for recommendation
- Easy-to-understand visualizations

**6. Continuous Refinement:**
- Monitor override rates by alert type
- Disable or modify frequently overridden alerts
- Gather user feedback on alert utility
- Rapid iteration based on real-world use
- A/B testing of alert designs

**7. Transparent Performance:**
- Show AI confidence levels
- Acknowledge uncertainty
- Display track record of alert accuracy
- Build trust through transparency

### 8.6 Equity-Centered AI Implementation

**Implementation Science with Equity Lens:**

Recent calls emphasize integrating equity from earliest stages (PMID: 35101088). Every project in implementation science should include an equity focus (PMID: 33740999).

**Assessment Phase:**
- Conduct health equity impact assessment before implementation
- Analyze AI performance across demographic subgroups
- Identify potential for bias or disparate impact
- Engage diverse communities in planning (PMID: 30906154)

**Design Phase:**
- Use representative, diverse training data
- Implement fairness constraints in algorithms
- Test extensively across populations
- Design for accessibility (language, literacy, disability)

**Implementation Phase:**
- Monitor adoption and use across subgroups
- Ensure equitable access to AI-enabled care
- Provide culturally appropriate training
- Address digital literacy barriers
- Prevent AI from exacerbating existing disparities (PMID: 32164706)

**Evaluation Phase:**
- Assess outcomes by race, ethnicity, language, SES, geography
- Monitor for differential performance
- Evaluate equity of access and benefit
- Report stratified outcomes transparently

**Continuous Improvement:**
- Ongoing bias monitoring and mitigation
- Community engagement and accountability
- Responsive to disparities identified
- Adapt AI and implementation strategies to promote equity

**AHA Scientific Statement:**
A 2022 American Heart Association scientific statement on leveraging implementation science for cardiovascular health equity highlights gaps including lack of stakeholder engagement, rigorous mixed methods, and equity-informed theoretical frameworks (PMID: 36214131).

---

## 9. Research Gaps and Future Directions

### 9.1 Implementation Science Gaps for AI

**1. AI-Specific Implementation Strategies:**

Current Gap:
- ERIC compilation developed for general healthcare interventions (PMID: 25889199)
- Unclear which strategies are most effective specifically for AI
- Limited evidence on AI-specific adaptations
- Lack of guidance on matching strategies to AI-specific barriers

Research Needed:
- Comparative effectiveness studies of implementation strategies for AI
- Development of AI-specific strategy taxonomy
- Understanding mechanisms by which strategies work for AI
- Contextual factors moderating strategy effectiveness

**2. Fidelity and Adaptation for AI:**

Current Gap:
- Unclear what constitutes "core components" of AI interventions requiring fidelity
- Limited guidance on appropriate local adaptation of AI tools
- Tension between standardization for performance monitoring and local tailoring
- Unknown effects of interface customization on outcomes

Research Needed:
- Framework for identifying core vs. adaptable AI components
- Studies examining impact of adaptations on AI effectiveness
- Guidance on balancing standardization with local needs
- Best practices for managing AI evolution while maintaining fidelity

**3. Sustainability of AI Interventions:**

Current Gap:
- Limited long-term follow-up of AI implementations
- Unknown factors predicting AI sustainability vs. discontinuation
- Lack of evidence on costs of sustaining AI systems
- Unclear how to maintain AI performance over time

Research Needed:
- Longitudinal studies following AI implementations 3+ years
- Identification of sustainability determinants specific to AI
- Cost-effectiveness of sustained vs. discontinued AI
- Strategies for maintaining AI relevance as practice evolves
- Managing model updates while preserving integration

**4. Scale-Up of AI Across Diverse Contexts:**

Current Gap:
- Limited evidence on scaling AI beyond single health systems
- Unknown how to maintain AI performance across diverse populations
- Challenges of generalizing AI across different EHR systems
- Lack of frameworks for AI scale-up

Research Needed:
- Multi-site AI implementation studies
- Strategies for ensuring AI equity at scale
- Approaches to managing technical heterogeneity
- Economic models for AI scale-up
- Policy interventions facilitating spread

**5. Measuring AI Implementation:**

Current Gap:
- Lack of validated AI-specific implementation outcome measures
- Unclear how to measure AI fidelity
- Limited tools for assessing AI readiness
- Insufficient metrics for AI-specific barriers

Research Needed:
- Development and validation of AI implementation measures
- Standardized fidelity assessment tools
- AI readiness assessment instruments
- Common data elements for AI implementation research

### 9.2 Methodological Gaps

**1. Implementation Science Designs for AI:**

Current Gap:
- Traditional implementation trials may not suit rapidly evolving AI
- Long trial timelines conflict with AI innovation pace
- Difficulty standardizing "intervention" when AI continuously learning
- Limited use of novel designs

Research Needed:
- Adaptive trial designs for AI implementation
- Hybrid effectiveness-implementation designs (PMID: 22310560)
- Sequential multiple assignment randomized trials (SMART)
- Methods for evaluating continuously evolving AI
- Real-world evidence generation approaches

**2. Economic Evaluation:**

Current Gap:
- Limited cost-effectiveness analyses of AI implementation
- Unknown costs of implementation vs. maintenance
- Unclear return on implementation investment timelines
- Budget impact not well characterized

Research Needed:
- Comprehensive implementation cost assessments
- Cost-effectiveness analyses including implementation costs
- Budget impact models for AI implementation
- Value of implementation frameworks (do they improve ROI?)

**3. Mixed Methods Integration:**

Current Gap:
- Heavy reliance on quantitative implementation metrics
- Insufficient qualitative understanding of AI implementation processes
- Limited integration of quantitative and qualitative findings

Research Needed:
- Mixed methods implementation studies
- Qualitative process evaluations
- Mechanisms of action research
- User experience research
- Ethnographic studies of AI integration

### 9.3 Context and Setting Gaps

**1. Implementation in Resource-Constrained Settings:**

Current Gap:
- Most AI implementation research in well-resourced academic centers
- Limited evidence from community hospitals, rural settings
- Unknown barriers and facilitators in low-resource contexts
- Lack of guidance for resource-limited implementations

Research Needed:
- AI implementation studies in diverse settings
- Strategies effective in resource constraints
- Adaptations for community and rural contexts
- Minimum infrastructure requirements

**2. Primary Care Implementation:**

Current Gap:
- Disproportionate focus on hospital/specialty care settings
- Limited AI implementation research in primary care
- Unknown how primary care context affects implementation
- Different workflow, resources, and priorities

Research Needed:
- Primary care-specific AI implementation studies
- Understanding primary care implementation barriers
- Strategies effective in ambulatory settings
- Integration with existing primary care quality improvement

**3. Global South Implementation:**

Current Gap:
- Vast majority of AI implementation research in high-income countries
- Limited evidence from low- and middle-income countries (LMICs)
- Different contextual factors (infrastructure, workforce, disease burden)
- Potential for different barriers and facilitators

Research Needed:
- AI implementation studies in LMICs
- Context-appropriate implementation strategies (CFIR for LMICs, PMID: 32164692)
- Understanding cultural and health system factors
- South-South learning and adaptation

### 9.4 Stakeholder and System Gaps

**1. Patient and Community Engagement:**

Current Gap:
- Limited research on patient perspectives on AI implementation
- Insufficient community engagement in AI deployment decisions
- Unknown patient preferences for AI involvement in care
- Lack of patient-centered AI implementation frameworks

Research Needed:
- Patient and community engagement strategies for AI
- Understanding patient trust in AI
- Patient preferences for AI transparency and control
- Shared decision-making with AI support
- Community-based participatory research on AI

**2. Organizational Learning:**

Current Gap:
- Limited understanding of how organizations learn from AI implementation
- Unknown how to build organizational AI capability
- Insufficient knowledge about learning health systems and AI
- Lack of evidence on knowledge management for AI

Research Needed:
- Organizational learning processes for AI
- Building AI capability and maturity
- Learning health system approaches to AI
- Knowledge management and transfer
- Cross-site learning mechanisms

**3. Policy and Regulation:**

Current Gap:
- Rapidly evolving regulatory landscape for AI
- Unknown impact of regulation on implementation
- Limited guidance for navigating regulatory requirements
- Unclear role of policy in facilitating implementation

Research Needed:
- Impact of regulatory approaches on AI adoption
- Policy interventions facilitating appropriate AI use
- Governance models supporting safe, effective AI
- Reimbursement and payment model effects
- Standard-setting and its implementation impact

### 9.5 Equity and Ethics Gaps

**1. Algorithmic Fairness Implementation:**

Current Gap:
- Limited evidence on implementing bias mitigation in practice
- Unknown effectiveness of fairness interventions
- Lack of validated equity monitoring approaches
- Insufficient guidance on equity-centered AI implementation

Research Needed:
- Real-world effectiveness of bias mitigation strategies
- Equity monitoring and accountability mechanisms
- Community oversight models
- Participatory approaches to AI fairness
- Trade-offs between fairness definitions

**2. Ethical Implementation:**

Current Gap:
- Limited research on ethics of AI implementation processes
- Unknown how to operationalize AI ethics principles
- Insufficient guidance on stakeholder engagement in ethics
- Lack of evidence on ethical review processes

Research Needed:
- Operationalizing AI ethics in implementation
- Stakeholder engagement in ethical decision-making
- Ethical frameworks for AI implementation (FUTURE-AI, PMID: 39909534)
- Transparency and accountability mechanisms
- Managing ethical tensions and trade-offs

### 9.6 De-implementation Gaps

**1. Stopping Low-Performing AI:**

Current Gap:
- Limited research on when and how to discontinue AI
- Unknown best practices for AI de-implementation
- Psychological and organizational barriers to stopping AI
- Lack of de-implementation frameworks for AI

Research Needed:
- Criteria for AI discontinuation decisions
- De-implementation strategies for AI
- Managing stakeholder reactions to AI discontinuation
- Learning from failed AI implementations
- Preventing perpetuation of ineffective or harmful AI

---

## 10. Conclusions and Recommendations

### 10.1 Key Takeaways

**1. Implementation Science Is Essential for AI Success:**
- Technical accuracy is necessary but insufficient for AI impact
- Implementation determines whether effective AI achieves population-level benefit
- Systematic use of implementation science frameworks improves outcomes
- Most AI implementation failures are implementation failures, not technical failures

**2. Multiple Frameworks Provide Complementary Insights:**
- No single framework captures all implementation dimensions
- Successful projects integrate frameworks strategically
- Updated CFIR (2022, PMID: 36309746), CFIR User Guide (2025, PMID: 40819067), and AI-specific frameworks (FUTURE-AI, SALIENT, CPI-AI) provide current guidance
- Match frameworks to implementation questions and phases
- Use pragmaticallyframeworks should help, not burden

**3. Barriers Are Multilevel and Require Multilevel Solutions:**
- Individual, organizational, and system barriers all matter
- 227 barriers identified for CDSS alone (PMID: 37495997)
- Single-level interventions rarely sufficient
- Multifaceted implementation strategies outperform single strategies (PMID: 38915102)
- Tailor strategies to identified barriers (ERIC compilation, PMID: 25889199)

**4. AI Presents Unique Implementation Challenges:**
- Explainability, bias, data quality, and dynamic nature create AI-specific barriers
- Traditional implementation approaches need adaptation for AI
- Equity must be central, not peripheral, to AI implementation (PMID: 35101088)
- Continuous monitoring essential given AI's dynamic nature (PMID: 40384926)

**5. Stakeholder Engagement Is Critical:**
- Early, sustained engagement of clinicians, patients, leaders essential
- Co-design improves usability and adoption
- Champions and opinion leaders accelerate spread (PMID: 38605304)
- Engagement builds trust necessary for AI acceptance

**6. Context Matters Profoundly:**
- Implementation strategies must fit local context (PMID: 32600396)
- What works in academic centers may not work elsewhere
- Systematic context assessment guides tailoring (COACH tool, PMID: 26276443)
- Balance standardization with necessary local adaptation

**7. Sustainability Requires Explicit Planning:**
- Only 30-40% of interventions sustained
- Sustainability cannot be an afterthought
- Plan for long-term maintenance from project inception (PMID: 29426341)
- Integration into workflows and budgets essential
- Demonstrate ongoing value to sustain resources and engagement

**8. Implementation Is a Process, Not an Event:**
- Phased approaches reduce risk and enable learning
- Expect and plan for iteration and adaptation
- Build learning systems for continuous improvement
- Long-term perspective essentialimplementation takes years

### 10.2 Recommendations for Practice

**For Healthcare Organizations Implementing AI:**

1. **Invest in Implementation Infrastructure:**
   - Dedicate resources to implementation, not just technology
   - Build implementation support teams
   - Allocate time for stakeholder engagement
   - Plan for 3-5 year implementation horizon

2. **Conduct Comprehensive Readiness Assessment:**
   - Use validated frameworks (Weiner ORIC, MUSIQ, CFIR)
   - Assess technical, organizational, and cultural readiness (PMID: 24410955)
   - Identify and address gaps before launch
   - Ensure leadership commitment and resource availability

3. **Engage Stakeholders Early and Often:**
   - Include clinicians in AI selection and design
   - Involve patients and communities
   - Create multidisciplinary governance structures (PMID: 40384926)
   - Build clinical champion networks (PMID: 39439009)

4. **Design for Workflow Integration:**
   - Embed AI in existing EHR systems (major barrier when lacking, PMID: 37495997)
   - Minimize disruption and burden
   - Provide actionable insights at point of care
   - Avoid alert fatigue through selective, tiered alerting (PMID: 38086417)

5. **Implement Robust Training:**
   - Train in both technical use and clinical rationale
   - Address AI literacy and appropriate use
   - Provide ongoing support beyond initial training
   - Ensure competency before independent use

6. **Monitor Continuously:**
   - Track implementation outcomes (Proctor framework, PMID: 20957426)
   - Monitor AI performance and user engagement
   - Assess equity across populations (PMID: 35101088)
   - Detect and respond to model drift (PMID: 40384926)

7. **Plan for Sustainability:**
   - Integrate into routine operations and budgets
   - Demonstrate ongoing value
   - Maintain stakeholder engagement
   - Adapt as context and evidence evolve (PMID: 29426341)

**For Researchers and Funders:**

1. **Study Implementation, Not Just Efficacy:**
   - Include implementation outcomes in AI studies (PMID: 20957426)
   - Conduct hybrid effectiveness-implementation trials (PMID: 22310560)
   - Follow implementations long-term (3+ years)
   - Use implementation science frameworks

2. **Address Research Gaps:**
   - Prioritize AI-specific implementation questions
   - Study diverse settings and populations
   - Examine equity and ethics empirically (PMID: 36214131)
   - Develop and validate AI implementation measures

3. **Fund Implementation:**
   - Allocate resources for implementation research
   - Support implementation capacity building
   - Fund long-term follow-up and sustainability studies
   - Incentivize knowledge translation and spread

**For Policymakers:**

1. **Create Enabling Environment:**
   - Align payment with AI value
   - Reduce regulatory barriers while ensuring safety
   - Support data infrastructure and interoperability
   - Fund implementation research

2. **Promote Equity:**
   - Require equity assessment for AI deployment (PMID: 33740999)
   - Incentivize AI use in underserved settings
   - Support diverse representation in AI development
   - Monitor and address disparities

3. **Build Learning Systems:**
   - Support communities of practice
   - Facilitate knowledge sharing across organizations
   - Create implementation toolkits and resources
   - Invest in implementation workforce development

### 10.3 Final Thoughts

The gap between AI's demonstrated potential and its realized impact in healthcare is fundamentally an implementation gap. Brilliant algorithms deployed poorly achieve nothing; good algorithms deployed well can transform care.

Implementation science provides the frameworks, evidence, and strategies needed to bridge this gap. The updated CFIR (PMID: 36309746), comprehensive ERIC strategies (PMID: 25889199), and emerging AI-specific frameworks (FUTURE-AI, SALIENT, CPI-AI) offer evidence-based guidance. However, AI's unique characteristicsits opacity, dynamism, data dependencies, and equity implicationsrequire thoughtful adaptation of implementation science principles, not their uncritical application.

The evidence is clear:
- **Alert fatigue is real:** 90-95% override rates undermine poorly designed systems (PMID: 28395667)
- **Barriers are multilevel:** 227 barriers identified across CDSS implementations (PMID: 37495997)
- **Context matters:** What works in one setting may fail in another (PMID: 32600396)
- **Equity is essential:** Implementation must center equity from the outset (PMID: 35101088)
- **Sustainability is challenging:** Only 30-40% of interventions sustained without explicit planning
- **Champions make a difference:** With mandate, time, and training, champions facilitate adoption (PMID: 38605304)

Success requires:
- **Humility:** Recognizing implementation complexity and learning from failures
- **Patience:** Understanding implementation takes years, not months
- **Rigor:** Systematically applying implementation science frameworks
- **Equity:** Centering fairness and justice, not treating them as afterthoughts
- **Pragmatism:** Using frameworks as tools, not dogma
- **Persistence:** Sustaining commitment through inevitable challenges

As AI becomes increasingly central to healthcare, implementation science must evolve alongside it. The field needs AI-specific implementation frameworks, strategies, and measures. It needs evidence from diverse settings and populations. It needs to grapple with unique AI challenges around explainability, bias, and continuous learning.

But the fundamental principles endure: understand context, engage stakeholders, address multilevel barriers, monitor and adapt, and plan for sustainability. Organizations that embrace these principles and invest in rigorous implementation will realize AI's potential to improve health and healthcare. Those that don't will join the long list of promising innovations that failed to achieve impactnot because they didn't work, but because they weren't implemented well.

The evidence base is growing. The frameworks are available. The strategies are tested. The choice is ours to make.

---

## References

*All references include PubMed identifiers (PMID) where available. See Section 7 for comprehensive citations of all referenced works organized by topic.*

---

**Document Information:**

**Prepared by:** Literature Review Synthesis with PubMed Evidence
**Date:** November 17, 2025
**Version:** 2.0 - Enhanced with PubMed citations and recent evidence (2024-2025)
**Purpose:** Supporting implementation planning for AI interventions in healthcare
**Intended Audience:** Implementation teams, researchers, clinicians, administrators, policymakers
**Primary Sources:** PubMed-indexed peer-reviewed publications
**Usage:** This document provides evidence-based guidance for planning, conducting, and evaluating implementation of AI interventions in healthcare settings. It should be used in conjunction with site-specific context assessment and stakeholder engagement.

**Document Status:** Version 2.0 - Comprehensive Literature Review with Enhanced PubMed Evidence
**Next Review:** Recommended annual update given rapid evolution of AI implementation evidence
**Total PMIDs Cited:** 100+ PubMed identifiers included throughout document

---

*End of Literature Review*
